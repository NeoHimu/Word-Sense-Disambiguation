{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### learning rate = 0.005, pos tags predicted using h_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open('../../Glove/word_embedding_glove', 'rb')\n",
    "word_embedding = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "word_embedding = word_embedding[: len(word_embedding)-1]\n",
    "\n",
    "f = open('../../Glove/vocab_glove', 'rb')\n",
    "vocab = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "word2id = dict((w, i) for i,w in enumerate(vocab))\n",
    "id2word = dict((i, w) for i,w in enumerate(vocab))\n",
    "\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "\n",
    "# Model Description\n",
    "model_name = 'model-aw-lex-2-2'\n",
    "model_dir = '../output/all-word/' + model_name\n",
    "save_dir = os.path.join(model_dir, \"save/\")\n",
    "log_dir = os.path.join(model_dir, \"log\")\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "with open('/data/aviraj/dataset/train_val_data_fine/all_word_lex','rb') as f:\n",
    "    train_data, val_data = pickle.load(f)    \n",
    "    \n",
    "# Parameters\n",
    "mode = 'train'\n",
    "num_senses = 45\n",
    "num_pos = 12\n",
    "batch_size = 64\n",
    "vocab_size = len(vocab)\n",
    "unk_vocab_size = 1\n",
    "word_emb_size = len(word_embedding[0])\n",
    "max_sent_size = 200\n",
    "hidden_size = 256\n",
    "num_filter = 256\n",
    "kernel_size = 5\n",
    "keep_prob = 0.4\n",
    "l2_lambda = 0.001\n",
    "init_lr = 0.001\n",
    "decay_steps = 500\n",
    "decay_rate = 0.99\n",
    "clip_norm = 1\n",
    "clipping = True\n",
    "moving_avg_deacy = 0.999\n",
    "num_gpus = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/clip_ops.py:110: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "device_num = 0\n",
    "tower_grads = []\n",
    "losses = []\n",
    "predictions = []\n",
    "predictions_pos = []\n",
    "\n",
    "x = tf.placeholder('int32', [num_gpus, batch_size, max_sent_size], name=\"x\")\n",
    "y = tf.placeholder('int32', [num_gpus, batch_size, max_sent_size], name=\"y\")\n",
    "y_pos = tf.placeholder('int32', [num_gpus, batch_size, max_sent_size], name=\"y\")\n",
    "x_mask  = tf.placeholder('bool', [num_gpus, batch_size, max_sent_size], name='x_mask') \n",
    "sense_mask  = tf.placeholder('bool', [num_gpus, batch_size, max_sent_size], name='sense_mask')\n",
    "is_train = tf.placeholder('bool', [], name='is_train')\n",
    "word_emb_mat = tf.placeholder('float', [None, word_emb_size], name='emb_mat')\n",
    "input_keep_prob = tf.cond(is_train,lambda:keep_prob, lambda:tf.constant(1.0))\n",
    "pretrain = tf.placeholder('bool', [], name=\"pretrain\")\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "learning_rate = tf.train.exponential_decay(init_lr, global_step, decay_steps, decay_rate, staircase=True)\n",
    "summaries = []\n",
    "\n",
    "def global_attention(input_x, input_mask, W_att):\n",
    "    h_masked = tf.boolean_mask(input_x, input_mask)\n",
    "    h_tanh = tf.tanh(h_masked)\n",
    "    u = tf.matmul(h_tanh, W_att)\n",
    "    a = tf.nn.softmax(u)\n",
    "    c = tf.reduce_sum(tf.multiply(h_tanh, a), 0)  \n",
    "    return c\n",
    "\n",
    "with tf.variable_scope(\"word_embedding\"):\n",
    "    unk_word_emb_mat = tf.get_variable(\"word_emb_mat\", dtype='float', shape=[unk_vocab_size, word_emb_size], initializer=tf.contrib.layers.xavier_initializer(uniform=True, seed=0, dtype=tf.float32))\n",
    "    final_word_emb_mat = tf.concat([word_emb_mat, unk_word_emb_mat], 0)\n",
    "\n",
    "with tf.variable_scope(tf.get_variable_scope()):\n",
    "    for gpu_idx in range(num_gpus):\n",
    "        if gpu_idx>int(num_gpus/2)-1:\n",
    "            device_num = 1\n",
    "        with tf.name_scope(\"model_{}\".format(gpu_idx)) as scope, tf.device('/gpu:%d' % device_num):\n",
    "\n",
    "            if gpu_idx > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            with tf.name_scope(\"word\"):\n",
    "                Wx = tf.nn.embedding_lookup(final_word_emb_mat, x[gpu_idx])  \n",
    "\n",
    "            x_len = tf.reduce_sum(tf.cast(x_mask[gpu_idx], 'int32'), 1)\n",
    "\n",
    "            with tf.variable_scope(\"lstm1\"):\n",
    "                cell_fw1 = tf.contrib.rnn.BasicLSTMCell(hidden_size,state_is_tuple=True)\n",
    "                cell_bw1 = tf.contrib.rnn.BasicLSTMCell(hidden_size,state_is_tuple=True)\n",
    "\n",
    "                d_cell_fw1 = tf.contrib.rnn.DropoutWrapper(cell_fw1, input_keep_prob=input_keep_prob)\n",
    "                d_cell_bw1 = tf.contrib.rnn.DropoutWrapper(cell_bw1, input_keep_prob=input_keep_prob)\n",
    "\n",
    "                (fw_h1, bw_h1), _ = tf.nn.bidirectional_dynamic_rnn(d_cell_fw1, d_cell_bw1, Wx, sequence_length=x_len, dtype='float', scope='lstm1')\n",
    "                h1 = tf.concat([fw_h1, bw_h1], 2)\n",
    "\n",
    "            with tf.variable_scope(\"lstm2\"):\n",
    "                cell_fw2 = tf.contrib.rnn.BasicLSTMCell(hidden_size,state_is_tuple=True)\n",
    "                cell_bw2 = tf.contrib.rnn.BasicLSTMCell(hidden_size,state_is_tuple=True)\n",
    "\n",
    "                d_cell_fw2 = tf.contrib.rnn.DropoutWrapper(cell_fw2, input_keep_prob=input_keep_prob)\n",
    "                d_cell_bw2 = tf.contrib.rnn.DropoutWrapper(cell_bw2, input_keep_prob=input_keep_prob)\n",
    "\n",
    "                (fw_h2, bw_h2), _ = tf.nn.bidirectional_dynamic_rnn(d_cell_fw2, d_cell_bw2, h1, sequence_length=x_len, dtype='float', scope='lstm2')\n",
    "                h = tf.concat([fw_h2, bw_h2], 2)\n",
    "\n",
    "            with tf.variable_scope(\"global_attention\"):\n",
    "                W_att = tf.get_variable(\"W_att\", shape=[2*hidden_size, 1], initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1, seed=gpu_idx*10))\n",
    "                c = tf.expand_dims(global_attention(h[0], x_mask[gpu_idx][0], W_att), 0)\n",
    "                for i in range(1, batch_size):\n",
    "                    c = tf.concat([c, tf.expand_dims(global_attention(h[i], x_mask[gpu_idx][i], W_att), 0)], 0)\n",
    "                cc = tf.expand_dims(c, 1)\n",
    "                c_final = tf.tile(cc, [1, max_sent_size, 1])\n",
    "    \n",
    "            h_final = tf.concat([c_final, h], 2)\n",
    "            flat_h_final = tf.reshape(h_final, [-1, tf.shape(h_final)[2]])\n",
    "            \n",
    "            with tf.variable_scope(\"hidden_layer\"):\n",
    "                W = tf.get_variable(\"W\", shape=[4*hidden_size, 2*hidden_size], initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1, seed=gpu_idx*20))\n",
    "                b = tf.get_variable(\"b\", shape=[2*hidden_size], initializer=tf.zeros_initializer())\n",
    "                drop_flat_h_final = tf.nn.dropout(flat_h_final, input_keep_prob)\n",
    "                flat_hl = tf.matmul(drop_flat_h_final, W) + b\n",
    "\n",
    "            with tf.variable_scope(\"softmax_layer\"):\n",
    "                W = tf.get_variable(\"W\", shape=[2*hidden_size, num_senses], initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1, seed=gpu_idx*20))\n",
    "                b = tf.get_variable(\"b\", shape=[num_senses], initializer=tf.zeros_initializer())\n",
    "                drop_flat_hl = tf.nn.dropout(flat_hl, input_keep_prob)\n",
    "                flat_logits_sense = tf.matmul(drop_flat_hl, W) + b\n",
    "                logits = tf.reshape(flat_logits_sense, [batch_size, max_sent_size, num_senses])\n",
    "                predictions.append(tf.argmax(logits, 2))\n",
    "\n",
    "            with tf.variable_scope(\"softmax_layer_pos\"):\n",
    "                W = tf.get_variable(\"W\", shape=[4*hidden_size, num_pos], initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1, seed=gpu_idx*30))\n",
    "                b = tf.get_variable(\"b\", shape=[num_pos], initializer=tf.zeros_initializer())\n",
    "                drop_flat_h_pos = tf.nn.dropout(flat_h_final, input_keep_prob)\n",
    "                flat_logits_pos = tf.matmul(drop_flat_h_pos, W) + b\n",
    "                logits_pos = tf.reshape(flat_logits_pos, [batch_size, max_sent_size, num_pos])\n",
    "                predictions_pos.append(tf.argmax(logits_pos, 2))\n",
    "\n",
    "\n",
    "            float_sense_mask = tf.cast(sense_mask[gpu_idx], 'float')\n",
    "            float_x_mask = tf.cast(x_mask[gpu_idx], 'float')\n",
    "\n",
    "            loss = tf.contrib.seq2seq.sequence_loss(logits, y[gpu_idx], float_sense_mask, name=\"loss\")\n",
    "            loss_pos = tf.contrib.seq2seq.sequence_loss(logits_pos, y_pos[gpu_idx], float_x_mask, name=\"loss_\")\n",
    "\n",
    "            l2_loss = l2_lambda * tf.losses.get_regularization_loss()\n",
    "\n",
    "            total_loss = tf.cond(pretrain, lambda:loss_pos, lambda:loss + loss_pos + l2_loss)\n",
    "\n",
    "            summaries.append(tf.summary.scalar(\"loss_{}\".format(gpu_idx), loss))\n",
    "            summaries.append(tf.summary.scalar(\"loss_pos_{}\".format(gpu_idx), loss_pos))\n",
    "            summaries.append(tf.summary.scalar(\"total_loss_{}\".format(gpu_idx), total_loss))\n",
    "\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            grads_vars = optimizer.compute_gradients(total_loss)\n",
    "\n",
    "            clipped_grads = grads_vars\n",
    "            if(clipping == True):\n",
    "                clipped_grads = [(tf.clip_by_norm(grad, clip_norm), var) for grad, var in clipped_grads]\n",
    "\n",
    "            tower_grads.append(clipped_grads)\n",
    "            losses.append(total_loss)\n",
    "\n",
    "tower_grads = average_gradients(tower_grads)\n",
    "losses = tf.add_n(losses)/len(losses)\n",
    "apply_grad_op = optimizer.apply_gradients(tower_grads, global_step=global_step)\n",
    "summaries.append(tf.summary.scalar('total_loss', losses))\n",
    "summaries.append(tf.summary.scalar('learning_rate', learning_rate))\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    summaries.append(tf.summary.histogram(var.op.name, var))\n",
    "\n",
    "variable_averages = tf.train.ExponentialMovingAverage(moving_avg_deacy, global_step)\n",
    "variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "train_op = tf.group(apply_grad_op, variables_averages_op)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "summary = tf.summary.merge(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "# print (device_lib.list_local_devices())\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())                          # For initializing all the variables\n",
    "summary_writer = tf.summary.FileWriter(log_dir, sess.graph)          # For writing Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_period = 100\n",
    "log_period = 100\n",
    "\n",
    "def model(xx, yy, yy_pos, mask, smask, train_cond=True, pretrain_cond=False):\n",
    "    num_batches = int(len(xx)/(batch_size*num_gpus))\n",
    "    _losses = 0\n",
    "    temp_loss = 0\n",
    "    preds_sense = []\n",
    "    true_sense = []\n",
    "    preds_pos = []\n",
    "    true_pos = []\n",
    "    \n",
    "    for j in range(num_batches): \n",
    "        \n",
    "        s = j * batch_size * num_gpus\n",
    "        e = (j+1) * batch_size * num_gpus\n",
    "        xx_re = xx[s:e].reshape([num_gpus, batch_size, -1])\n",
    "        yy_re = yy[s:e].reshape([num_gpus, batch_size, -1])\n",
    "        yy_pos_re = yy_pos[s:e].reshape([num_gpus, batch_size, -1])\n",
    "        mask_re = mask[s:e].reshape([num_gpus, batch_size, -1])\n",
    "        smask_re = smask[s:e].reshape([num_gpus, batch_size, -1])\n",
    " \n",
    "        feed_dict = {x:xx_re, y:yy_re, y_pos:yy_pos_re, x_mask:mask_re, sense_mask:smask_re, pretrain:pretrain_cond, is_train:train_cond, input_keep_prob:keep_prob, word_emb_mat:word_embedding}\n",
    "        \n",
    "        if(train_cond==True):\n",
    "            _, _loss, step, _summary = sess.run([train_op, losses, global_step, summary], feed_dict)\n",
    "            summary_writer.add_summary(_summary, step)\n",
    "            \n",
    "            temp_loss += _loss\n",
    "            if((j+1)%log_period==0):\n",
    "                print(\"Steps: {}\".format(step), \"Loss:{0:.4f}\".format(temp_loss/log_period), \", Current Loss: {0:.4f}\".format(_loss))\n",
    "                temp_loss = 0\n",
    "            if((j+1)%save_period==0):\n",
    "                saver.save(sess, save_path=save_dir)                         \n",
    "                \n",
    "        else:\n",
    "            _loss, pred, pred_pos = sess.run([total_loss, predictions, predictions_pos], feed_dict)\n",
    "            for i in range(num_gpus):\n",
    "                preds_sense.append(pred[i][smask_re[i]])\n",
    "                true_sense.append(yy_re[i][smask_re[i]])\n",
    "                preds_pos.append(pred_pos[i][mask_re[i]])\n",
    "                true_pos.append(yy_pos_re[i][mask_re[i]])\n",
    "\n",
    "        _losses +=_loss\n",
    "\n",
    "    if(train_cond==False): \n",
    "        sense_preds = []\n",
    "        sense_true = []\n",
    "        pos_preds = []\n",
    "        pos_true = []\n",
    "        \n",
    "        for preds in preds_sense:\n",
    "            for ps in preds:      \n",
    "                sense_preds.append(ps)  \n",
    "        for trues in true_sense:\n",
    "            for ts in trues:\n",
    "                sense_true.append(ts)\n",
    "        \n",
    "        for preds in preds_pos:\n",
    "            for ps in preds:      \n",
    "                pos_preds.append(ps)      \n",
    "        for trues in true_pos:\n",
    "            for ts in trues:\n",
    "                pos_true.append(ts)\n",
    "                \n",
    "        return _losses/num_batches, sense_preds, sense_true, pos_preds, pos_true\n",
    "\n",
    "    return _losses/num_batches, step\n",
    "\n",
    "def eval_score(yy, pred, yy_pos, pred_pos):\n",
    "    f1 = f1_score(yy, pred, average='macro')\n",
    "    accu = accuracy_score(yy, pred)\n",
    "    f1_pos = f1_score(yy_pos, pred_pos, average='macro')\n",
    "    accu_pos = accuracy_score(yy_pos, pred_pos)\n",
    "    return f1*100, accu*100, f1_pos*100, accu_pos*100\n",
    "\n",
    "def save_val_logs(temp):\n",
    "    try:\n",
    "        f = open(model_dir+ \"/val_logs\", \"rb\")\n",
    "        old = pickle.load(f)\n",
    "        f.close()\n",
    "        f = open(model_dir+ \"/val_logs\", \"wb\")\n",
    "        old.append(temp)\n",
    "        pickle.dump(old, f)\n",
    "    except FileNotFoundError:\n",
    "        f = open(model_dir+ \"/val_logs\", \"wb\")\n",
    "        pickle.dump([temp], f)\n",
    "        f.close()\n",
    "\n",
    "def save_train_logs(temp):\n",
    "    try:\n",
    "        f = open(model_dir+ \"/train_logs\", \"rb\")\n",
    "        old = pickle.load(f)\n",
    "        f.close()\n",
    "        f = open(model_dir+ \"/train_logs\", \"wb\")\n",
    "        old.append(temp)\n",
    "        pickle.dump(old, f)\n",
    "    except FileNotFoundError:\n",
    "        f = open(model_dir+ \"/train_logs\", \"wb\")\n",
    "        pickle.dump([temp], f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_id_train = train_data['x']\n",
    "mask_train = train_data['x_mask']\n",
    "sense_mask_train = train_data['sense_mask']\n",
    "y_train = train_data['y']\n",
    "y_pos_train = train_data['pos']\n",
    "\n",
    "x_id_val = val_data['x']\n",
    "mask_val = val_data['x_mask']\n",
    "sense_mask_val = val_data['sense_mask']\n",
    "y_val = val_data['y']\n",
    "y_pos_val = val_data['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 100 Loss:5.3674 , Current Loss: 2.1611\n",
      "Steps: 200 Loss:1.8464 , Current Loss: 1.0933\n",
      "Steps: 300 Loss:0.7623 , Current Loss: 0.5904\n",
      "Steps: 400 Loss:0.5191 , Current Loss: 0.4504\n",
      "Steps: 500 Loss:0.4213 , Current Loss: 0.3914\n",
      "Steps: 600 Loss:0.3600 , Current Loss: 0.3265\n",
      "Steps: 700 Loss:0.3219 , Current Loss: 0.3012\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "val_period = 1\n",
    "loss_collection = []\n",
    "val_collection = []\n",
    "pre_train_cond = True\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 800 Loss:5.2592 , Current Loss: 3.2679\n",
      "Steps: 900 Loss:3.0923 , Current Loss: 2.9597\n",
      "Steps: 1000 Loss:2.7754 , Current Loss: 2.5682\n",
      "Steps: 1100 Loss:2.5896 , Current Loss: 2.4611\n",
      "Steps: 1200 Loss:2.4808 , Current Loss: 2.3712\n",
      "Steps: 1300 Loss:2.4005 , Current Loss: 2.2374\n",
      "Steps: 1400 Loss:2.3364 , Current Loss: 2.4100\n",
      "Steps: 1500 Loss:2.2705 , Current Loss: 2.0756\n",
      "Steps: 1600 Loss:2.2372 , Current Loss: 2.3246\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 1700 Loss:2.1979 , Current Loss: 2.1717\n",
      "Steps: 1800 Loss:2.1544 , Current Loss: 2.2598\n",
      "Steps: 1900 Loss:2.1397 , Current Loss: 2.0750\n",
      "Steps: 2000 Loss:2.1085 , Current Loss: 2.1254\n",
      "Steps: 2100 Loss:2.0854 , Current Loss: 2.0996\n",
      "Steps: 2200 Loss:2.0505 , Current Loss: 2.1495\n",
      "Steps: 2300 Loss:2.0218 , Current Loss: 1.9948\n",
      "Steps: 2400 Loss:2.0117 , Current Loss: 1.8594\n",
      "Steps: 2500 Loss:1.9907 , Current Loss: 2.0386\n",
      "Steps: 2600 Loss:1.9779 , Current Loss: 1.8969\n",
      "Steps: 2700 Loss:1.9438 , Current Loss: 1.8520\n",
      "Steps: 2800 Loss:1.9395 , Current Loss: 1.8981\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 2900 Loss:1.9224 , Current Loss: 2.0388\n",
      "Steps: 3000 Loss:1.9055 , Current Loss: 1.8295\n",
      "Steps: 3100 Loss:1.9157 , Current Loss: 1.9636\n",
      "Steps: 3200 Loss:1.8722 , Current Loss: 1.8092\n",
      "Steps: 3300 Loss:1.8776 , Current Loss: 1.8689\n",
      "Steps: 3400 Loss:1.8618 , Current Loss: 1.8058\n",
      "Steps: 3500 Loss:1.8538 , Current Loss: 1.8207\n",
      "Steps: 3600 Loss:1.8435 , Current Loss: 1.7502\n",
      "Steps: 3700 Loss:1.8352 , Current Loss: 1.7308\n",
      "Steps: 3800 Loss:1.8233 , Current Loss: 1.8277\n",
      "Steps: 3900 Loss:1.8185 , Current Loss: 1.7640\n",
      "Steps: 4000 Loss:1.8215 , Current Loss: 1.7741\n",
      "Steps: 4100 Loss:1.8025 , Current Loss: 1.9120\n",
      "Steps: 4200 Loss:1.7802 , Current Loss: 1.9101\n",
      "Steps: 4300 Loss:1.7838 , Current Loss: 1.7946\n",
      "Steps: 4400 Loss:1.7680 , Current Loss: 1.8407\n",
      "Steps: 4500 Loss:1.7742 , Current Loss: 1.7113\n",
      "Epoch: 1 , Step: 4571 , loss: 1.8357 , Time: 10830.0\n",
      "Model Saved\n",
      "Steps: 4671 Loss:1.7520 , Current Loss: 1.8807\n",
      "Steps: 4771 Loss:1.7544 , Current Loss: 1.7509\n",
      "Steps: 4871 Loss:1.7207 , Current Loss: 1.7822\n",
      "Steps: 4971 Loss:1.7353 , Current Loss: 1.7159\n",
      "Steps: 5071 Loss:1.7199 , Current Loss: 1.6569\n",
      "Steps: 5171 Loss:1.7154 , Current Loss: 1.6591\n",
      "Steps: 5271 Loss:1.7090 , Current Loss: 1.7203\n",
      "Steps: 5371 Loss:1.7074 , Current Loss: 1.6619\n",
      "Steps: 5471 Loss:1.6984 , Current Loss: 1.6774\n",
      "Steps: 5571 Loss:1.6823 , Current Loss: 1.6743\n",
      "Steps: 5671 Loss:1.6938 , Current Loss: 1.6698\n",
      "Steps: 5771 Loss:1.6773 , Current Loss: 1.7111\n",
      "Steps: 5871 Loss:1.6871 , Current Loss: 1.7278\n",
      "Steps: 5971 Loss:1.6561 , Current Loss: 1.6354\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 6071 Loss:1.6556 , Current Loss: 1.5446\n",
      "Steps: 6171 Loss:1.6692 , Current Loss: 1.6034\n",
      "Steps: 6271 Loss:1.6521 , Current Loss: 1.7231\n",
      "Steps: 6371 Loss:1.6478 , Current Loss: 1.5646\n",
      "Steps: 6471 Loss:1.6522 , Current Loss: 1.6472\n",
      "Steps: 6571 Loss:1.6295 , Current Loss: 1.6840\n",
      "Steps: 6671 Loss:1.6433 , Current Loss: 1.7914\n",
      "Steps: 6771 Loss:1.6301 , Current Loss: 1.7140\n",
      "Steps: 6871 Loss:1.6374 , Current Loss: 1.5301\n",
      "Steps: 6971 Loss:1.6221 , Current Loss: 1.6431\n",
      "Steps: 7071 Loss:1.6281 , Current Loss: 1.6017\n",
      "Steps: 7171 Loss:1.6215 , Current Loss: 1.5612\n",
      "Steps: 7271 Loss:1.6271 , Current Loss: 1.6493\n",
      "Steps: 7371 Loss:1.5998 , Current Loss: 1.6637\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 7471 Loss:1.6069 , Current Loss: 1.5844\n",
      "Steps: 7571 Loss:1.6077 , Current Loss: 1.7320\n",
      "Steps: 7671 Loss:1.5837 , Current Loss: 1.7231\n",
      "Steps: 7771 Loss:1.6001 , Current Loss: 1.5729\n",
      "Steps: 7871 Loss:1.5886 , Current Loss: 1.5351\n",
      "Steps: 7971 Loss:1.5870 , Current Loss: 1.5669\n",
      "Steps: 8071 Loss:1.5684 , Current Loss: 1.6432\n",
      "Steps: 8171 Loss:1.5882 , Current Loss: 1.5069\n",
      "Steps: 8271 Loss:1.5812 , Current Loss: 1.4797\n",
      "Steps: 8371 Loss:1.5878 , Current Loss: 1.4984\n",
      "Steps: 8471 Loss:1.5590 , Current Loss: 1.4710\n",
      "Steps: 8571 Loss:1.5742 , Current Loss: 1.5925\n",
      "Steps: 8671 Loss:1.5627 , Current Loss: 1.5128\n",
      "Steps: 8771 Loss:1.5530 , Current Loss: 1.5961\n",
      "Steps: 8871 Loss:1.5635 , Current Loss: 1.4247\n",
      "Steps: 8971 Loss:1.5535 , Current Loss: 1.5449\n",
      "Steps: 9071 Loss:1.5468 , Current Loss: 1.5294\n",
      "Epoch: 1 , Step: 9142 , loss: 1.5763 , Time: 11145.0\n",
      "Model Saved\n",
      "Steps: 9242 Loss:1.5506 , Current Loss: 1.6275\n",
      "Steps: 9342 Loss:1.5297 , Current Loss: 1.6551\n",
      "Steps: 9442 Loss:1.5374 , Current Loss: 1.5336\n",
      "Steps: 9542 Loss:1.5421 , Current Loss: 1.5231\n",
      "Steps: 9642 Loss:1.5377 , Current Loss: 1.5836\n",
      "Steps: 9742 Loss:1.5459 , Current Loss: 1.5988\n",
      "Steps: 9842 Loss:1.5375 , Current Loss: 1.5844\n",
      "Steps: 9942 Loss:1.5228 , Current Loss: 1.5458\n",
      "Steps: 10042 Loss:1.5288 , Current Loss: 1.5178\n",
      "Steps: 10142 Loss:1.5109 , Current Loss: 1.4716\n",
      "Steps: 10242 Loss:1.5213 , Current Loss: 1.6158\n",
      "Steps: 10342 Loss:1.5188 , Current Loss: 1.6163\n",
      "Steps: 10442 Loss:1.5258 , Current Loss: 1.4654\n",
      "Steps: 10542 Loss:1.5228 , Current Loss: 1.3776\n",
      "Steps: 10642 Loss:1.5066 , Current Loss: 1.4391\n",
      "Steps: 10742 Loss:1.5172 , Current Loss: 1.4843\n",
      "Steps: 10842 Loss:1.5085 , Current Loss: 1.4963\n",
      "Epoch: 2 , Step: 10913 , loss: 1.5256 , Time: 10487.6\n",
      "Model Saved\n",
      "Val: F1 Score:50.81 Accuracy:58.41  POS: F1 Score:86.37 Accuracy:93.22 Loss:1.5042 , Time: 2232.5\n",
      "Steps: 11013 Loss:1.5027 , Current Loss: 1.5162\n",
      "Steps: 11113 Loss:1.4915 , Current Loss: 1.3915\n",
      "Steps: 11213 Loss:1.4961 , Current Loss: 1.5824\n",
      "Steps: 11313 Loss:1.4966 , Current Loss: 1.4410\n",
      "Steps: 11413 Loss:1.4959 , Current Loss: 1.4508\n",
      "Steps: 11513 Loss:1.4954 , Current Loss: 1.3467\n",
      "Steps: 11613 Loss:1.4930 , Current Loss: 1.5656\n",
      "Steps: 11713 Loss:1.4983 , Current Loss: 1.5559\n",
      "Steps: 11813 Loss:1.4833 , Current Loss: 1.5548\n",
      "Steps: 11913 Loss:1.4946 , Current Loss: 1.4607\n",
      "Steps: 12013 Loss:1.4876 , Current Loss: 1.5285\n",
      "Steps: 12113 Loss:1.4980 , Current Loss: 1.6358\n",
      "Steps: 12213 Loss:1.4680 , Current Loss: 1.5376\n",
      "Steps: 12313 Loss:1.4799 , Current Loss: 1.4463\n",
      "Steps: 12413 Loss:1.4770 , Current Loss: 1.4622\n",
      "Steps: 12513 Loss:1.4746 , Current Loss: 1.4551\n",
      "Steps: 12613 Loss:1.4776 , Current Loss: 1.5394\n",
      "Epoch: 3 , Step: 12684 , loss: 1.4880 , Time: 11446.9\n",
      "Model Saved\n",
      "Steps: 12784 Loss:1.4777 , Current Loss: 1.3830\n",
      "Steps: 12884 Loss:1.4579 , Current Loss: 1.4257\n",
      "Steps: 12984 Loss:1.4668 , Current Loss: 1.5265\n",
      "Steps: 13084 Loss:1.4600 , Current Loss: 1.5226\n",
      "Steps: 13184 Loss:1.4798 , Current Loss: 1.4580\n",
      "Steps: 13284 Loss:1.4553 , Current Loss: 1.4884\n",
      "Steps: 13384 Loss:1.4588 , Current Loss: 1.3889\n",
      "Steps: 13484 Loss:1.4531 , Current Loss: 1.5298\n",
      "Steps: 13584 Loss:1.4540 , Current Loss: 1.6140\n",
      "Steps: 13684 Loss:1.4422 , Current Loss: 1.4442\n",
      "Steps: 13784 Loss:1.4643 , Current Loss: 1.4205\n",
      "Steps: 13884 Loss:1.4601 , Current Loss: 1.3460\n",
      "Steps: 13984 Loss:1.4487 , Current Loss: 1.5766\n",
      "Steps: 14084 Loss:1.4452 , Current Loss: 1.4258\n",
      "Steps: 14184 Loss:1.4439 , Current Loss: 1.5576\n",
      "Steps: 14284 Loss:1.4466 , Current Loss: 1.5019\n",
      "Steps: 14384 Loss:1.4426 , Current Loss: 1.5075\n",
      "Epoch: 4 , Step: 14455 , loss: 1.4559 , Time: 11366.9\n",
      "Model Saved\n",
      "Val: F1 Score:53.23 Accuracy:60.14  POS: F1 Score:86.87 Accuracy:93.46 Loss:1.4424 , Time: 2291.6\n",
      "Steps: 14555 Loss:1.4536 , Current Loss: 1.2870\n",
      "Steps: 14655 Loss:1.4334 , Current Loss: 1.5017\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 14755 Loss:1.4351 , Current Loss: 1.3660\n",
      "Steps: 14855 Loss:1.4388 , Current Loss: 1.5125\n",
      "Steps: 14955 Loss:1.4286 , Current Loss: 1.4990\n",
      "Steps: 15055 Loss:1.4329 , Current Loss: 1.3833\n",
      "Steps: 15155 Loss:1.4495 , Current Loss: 1.5531\n",
      "Steps: 15255 Loss:1.4287 , Current Loss: 1.5906\n",
      "Steps: 15355 Loss:1.4412 , Current Loss: 1.3393\n",
      "Steps: 15455 Loss:1.4202 , Current Loss: 1.4346\n",
      "Steps: 15555 Loss:1.4190 , Current Loss: 1.4040\n",
      "Steps: 15655 Loss:1.4353 , Current Loss: 1.3760\n",
      "Steps: 15755 Loss:1.4289 , Current Loss: 1.3814\n",
      "Steps: 15855 Loss:1.4229 , Current Loss: 1.3767\n",
      "Steps: 15955 Loss:1.4179 , Current Loss: 1.4015\n",
      "Steps: 16055 Loss:1.4180 , Current Loss: 1.5298\n",
      "Steps: 16155 Loss:1.4209 , Current Loss: 1.2755\n",
      "Steps: 16255 Loss:1.4120 , Current Loss: 1.4360\n",
      "Steps: 16355 Loss:1.4028 , Current Loss: 1.3763\n",
      "Epoch: 1 , Step: 16426 , loss: 1.4262 , Time: 11455.7\n",
      "Model Saved\n",
      "Steps: 16526 Loss:1.4044 , Current Loss: 1.3799\n",
      "Steps: 16626 Loss:1.4269 , Current Loss: 1.3468\n",
      "Steps: 16726 Loss:1.4081 , Current Loss: 1.4342\n",
      "Steps: 16826 Loss:1.4001 , Current Loss: 1.3801\n",
      "Steps: 16926 Loss:1.4172 , Current Loss: 1.5385\n",
      "Steps: 17026 Loss:1.4035 , Current Loss: 1.4137\n",
      "Steps: 17126 Loss:1.4160 , Current Loss: 1.3437\n",
      "Steps: 17226 Loss:1.4171 , Current Loss: 1.4774\n",
      "Steps: 17326 Loss:1.3918 , Current Loss: 1.4090\n",
      "Steps: 17426 Loss:1.4063 , Current Loss: 1.3029\n",
      "Steps: 17526 Loss:1.4032 , Current Loss: 1.4627\n",
      "Steps: 17626 Loss:1.3987 , Current Loss: 1.4050\n",
      "Steps: 17726 Loss:1.4105 , Current Loss: 1.3910\n",
      "Steps: 17826 Loss:1.4001 , Current Loss: 1.3540\n",
      "Steps: 17926 Loss:1.4076 , Current Loss: 1.4535\n",
      "Steps: 18026 Loss:1.3935 , Current Loss: 1.4585\n",
      "Steps: 18126 Loss:1.4064 , Current Loss: 1.3808\n",
      "Epoch: 2 , Step: 18197 , loss: 1.4063 , Time: 11254.4\n",
      "Model Saved\n",
      "Val: F1 Score:54.73 Accuracy:61.29  POS: F1 Score:87.43 Accuracy:93.67 Loss:1.4033 , Time: 2387.9\n",
      "Steps: 18297 Loss:1.3967 , Current Loss: 1.3402\n",
      "Steps: 18397 Loss:1.3996 , Current Loss: 1.3553\n",
      "Steps: 18497 Loss:1.3963 , Current Loss: 1.4399\n",
      "Steps: 18597 Loss:1.3979 , Current Loss: 1.4076\n",
      "Steps: 18697 Loss:1.3880 , Current Loss: 1.3649\n",
      "Steps: 18797 Loss:1.3783 , Current Loss: 1.3338\n",
      "Steps: 18897 Loss:1.3833 , Current Loss: 1.3863\n",
      "Steps: 18997 Loss:1.3934 , Current Loss: 1.3690\n",
      "Steps: 19097 Loss:1.3756 , Current Loss: 1.3399\n",
      "Steps: 19197 Loss:1.3816 , Current Loss: 1.4303\n",
      "Steps: 19297 Loss:1.3838 , Current Loss: 1.3300\n",
      "Steps: 19397 Loss:1.3685 , Current Loss: 1.3854\n",
      "Steps: 19497 Loss:1.3838 , Current Loss: 1.2536\n",
      "Steps: 19597 Loss:1.3907 , Current Loss: 1.4379\n",
      "Steps: 19697 Loss:1.3868 , Current Loss: 1.3105\n",
      "Steps: 19797 Loss:1.3799 , Current Loss: 1.2998\n",
      "Steps: 19897 Loss:1.3695 , Current Loss: 1.3300\n",
      "Epoch: 3 , Step: 19968 , loss: 1.3849 , Time: 10832.0\n",
      "Model Saved\n",
      "Steps: 20068 Loss:1.3738 , Current Loss: 1.3412\n",
      "Steps: 20168 Loss:1.3635 , Current Loss: 1.3294\n",
      "Steps: 20268 Loss:1.3598 , Current Loss: 1.4813\n",
      "Steps: 20368 Loss:1.3806 , Current Loss: 1.4358\n",
      "Steps: 20468 Loss:1.3745 , Current Loss: 1.3304\n",
      "Steps: 20568 Loss:1.3607 , Current Loss: 1.4185\n",
      "Steps: 20668 Loss:1.3684 , Current Loss: 1.3952\n",
      "Steps: 20768 Loss:1.3748 , Current Loss: 1.3714\n",
      "Steps: 20868 Loss:1.3650 , Current Loss: 1.4259\n",
      "Steps: 20968 Loss:1.3698 , Current Loss: 1.3069\n",
      "Steps: 21068 Loss:1.3764 , Current Loss: 1.4381\n",
      "Steps: 21168 Loss:1.3688 , Current Loss: 1.2957\n",
      "Steps: 21268 Loss:1.3781 , Current Loss: 1.2825\n",
      "Steps: 21368 Loss:1.3631 , Current Loss: 1.3825\n",
      "Steps: 21468 Loss:1.3611 , Current Loss: 1.4548\n",
      "Steps: 21568 Loss:1.3706 , Current Loss: 1.2979\n",
      "Steps: 21668 Loss:1.3803 , Current Loss: 1.4752\n",
      "Epoch: 4 , Step: 21739 , loss: 1.3696 , Time: 10520.3\n",
      "Model Saved\n",
      "Val: F1 Score:55.58 Accuracy:62.15  POS: F1 Score:87.78 Accuracy:93.80 Loss:1.3649 , Time: 2252.1\n",
      "Steps: 21839 Loss:1.3650 , Current Loss: 1.4359\n",
      "Steps: 21939 Loss:1.3427 , Current Loss: 1.2981\n",
      "Steps: 22039 Loss:1.3666 , Current Loss: 1.3261\n",
      "Steps: 22139 Loss:1.3687 , Current Loss: 1.3859\n",
      "Steps: 22239 Loss:1.3495 , Current Loss: 1.2877\n",
      "Steps: 22339 Loss:1.3559 , Current Loss: 1.3003\n",
      "Steps: 22439 Loss:1.3570 , Current Loss: 1.3128\n",
      "Steps: 22539 Loss:1.3641 , Current Loss: 1.3142\n",
      "Steps: 22639 Loss:1.3572 , Current Loss: 1.2586\n",
      "Steps: 22739 Loss:1.3428 , Current Loss: 1.2611\n",
      "Steps: 22839 Loss:1.3577 , Current Loss: 1.4190\n",
      "Steps: 22939 Loss:1.3537 , Current Loss: 1.2906\n",
      "Steps: 23039 Loss:1.3458 , Current Loss: 1.3771\n",
      "Steps: 23139 Loss:1.3525 , Current Loss: 1.3314\n",
      "Steps: 23239 Loss:1.3655 , Current Loss: 1.3346\n",
      "Steps: 23339 Loss:1.3398 , Current Loss: 1.2365\n",
      "Steps: 23439 Loss:1.3484 , Current Loss: 1.4154\n",
      "Epoch: 5 , Step: 23510 , loss: 1.3545 , Time: 11362.3\n",
      "Model Saved\n",
      "Steps: 23610 Loss:1.3411 , Current Loss: 1.2784\n",
      "Steps: 23710 Loss:1.3548 , Current Loss: 1.3906\n",
      "Steps: 23810 Loss:1.3417 , Current Loss: 1.2277\n",
      "Steps: 23910 Loss:1.3422 , Current Loss: 1.2682\n",
      "Steps: 24010 Loss:1.3546 , Current Loss: 1.3621\n",
      "Steps: 24110 Loss:1.3335 , Current Loss: 1.2713\n",
      "Steps: 24210 Loss:1.3393 , Current Loss: 1.2465\n",
      "Steps: 24310 Loss:1.3373 , Current Loss: 1.2674\n",
      "Steps: 24410 Loss:1.3533 , Current Loss: 1.3683\n",
      "Steps: 24510 Loss:1.3394 , Current Loss: 1.3152\n",
      "Steps: 24610 Loss:1.3432 , Current Loss: 1.2379\n",
      "Steps: 24710 Loss:1.3325 , Current Loss: 1.3042\n",
      "Steps: 24810 Loss:1.3444 , Current Loss: 1.3235\n",
      "Steps: 24910 Loss:1.3357 , Current Loss: 1.2559\n",
      "Steps: 25010 Loss:1.3462 , Current Loss: 1.3230\n",
      "Steps: 25110 Loss:1.3471 , Current Loss: 1.4181\n",
      "Steps: 25210 Loss:1.3247 , Current Loss: 1.2526\n",
      "Epoch: 6 , Step: 25281 , loss: 1.3416 , Time: 10594.9\n",
      "Model Saved\n",
      "Val: F1 Score:56.24 Accuracy:62.81  POS: F1 Score:87.99 Accuracy:93.95 Loss:1.3414 , Time: 2173.5\n",
      "Steps: 25381 Loss:1.3277 , Current Loss: 1.3951\n",
      "Steps: 25481 Loss:1.3392 , Current Loss: 1.3639\n",
      "Steps: 25581 Loss:1.3266 , Current Loss: 1.3285\n",
      "Steps: 25681 Loss:1.3289 , Current Loss: 1.3744\n",
      "Steps: 25781 Loss:1.3316 , Current Loss: 1.3213\n",
      "Steps: 25881 Loss:1.3325 , Current Loss: 1.1587\n",
      "Steps: 25981 Loss:1.3335 , Current Loss: 1.3964\n",
      "Steps: 26081 Loss:1.3124 , Current Loss: 1.3280\n",
      "Steps: 26181 Loss:1.3254 , Current Loss: 1.3194\n",
      "Steps: 26281 Loss:1.3408 , Current Loss: 1.3805\n",
      "Steps: 26381 Loss:1.3319 , Current Loss: 1.4149\n",
      "Steps: 26481 Loss:1.3260 , Current Loss: 1.2638\n",
      "Steps: 26581 Loss:1.3318 , Current Loss: 1.3410\n",
      "Steps: 26681 Loss:1.3279 , Current Loss: 1.2694\n",
      "Steps: 26781 Loss:1.3274 , Current Loss: 1.1946\n",
      "Steps: 26881 Loss:1.3375 , Current Loss: 1.4753\n",
      "Steps: 26981 Loss:1.3150 , Current Loss: 1.2100\n",
      "Epoch: 7 , Step: 27052 , loss: 1.3288 , Time: 10398.7\n",
      "Model Saved\n",
      "Steps: 27152 Loss:1.3152 , Current Loss: 1.4097\n",
      "Steps: 27252 Loss:1.3087 , Current Loss: 1.3323\n",
      "Steps: 27352 Loss:1.3243 , Current Loss: 1.3111\n",
      "Steps: 27452 Loss:1.3243 , Current Loss: 1.3721\n",
      "Steps: 27552 Loss:1.3131 , Current Loss: 1.3447\n",
      "Steps: 27652 Loss:1.3207 , Current Loss: 1.2408\n",
      "Steps: 27752 Loss:1.3164 , Current Loss: 1.2382\n",
      "Steps: 27852 Loss:1.3136 , Current Loss: 1.4002\n",
      "Steps: 27952 Loss:1.3245 , Current Loss: 1.3121\n",
      "Steps: 28052 Loss:1.3082 , Current Loss: 1.4181\n",
      "Steps: 28152 Loss:1.3161 , Current Loss: 1.2800\n",
      "Steps: 28252 Loss:1.3126 , Current Loss: 1.3594\n",
      "Steps: 28352 Loss:1.3120 , Current Loss: 1.3193\n",
      "Steps: 28452 Loss:1.3195 , Current Loss: 1.4773\n",
      "Steps: 28552 Loss:1.3263 , Current Loss: 1.4418\n",
      "Steps: 28652 Loss:1.3325 , Current Loss: 1.3243\n",
      "Steps: 28752 Loss:1.3131 , Current Loss: 1.2488\n",
      "Epoch: 8 , Step: 28823 , loss: 1.3173 , Time: 10871.4\n",
      "Model Saved\n",
      "Val: F1 Score:57.12 Accuracy:63.48  POS: F1 Score:88.26 Accuracy:94.05 Loss:1.3132 , Time: 2316.8\n",
      "Steps: 28923 Loss:1.3050 , Current Loss: 1.1787\n",
      "Steps: 29023 Loss:1.3165 , Current Loss: 1.3113\n",
      "Steps: 29123 Loss:1.3141 , Current Loss: 1.3353\n",
      "Steps: 29223 Loss:1.3225 , Current Loss: 1.4125\n",
      "Steps: 29323 Loss:1.3014 , Current Loss: 1.3089\n",
      "Steps: 29423 Loss:1.3185 , Current Loss: 1.3489\n",
      "Steps: 29523 Loss:1.3071 , Current Loss: 1.3272\n",
      "Steps: 29623 Loss:1.2999 , Current Loss: 1.2402\n",
      "Steps: 29723 Loss:1.3187 , Current Loss: 1.2765\n",
      "Steps: 29823 Loss:1.3079 , Current Loss: 1.2828\n",
      "Steps: 29923 Loss:1.3088 , Current Loss: 1.3789\n",
      "Steps: 30023 Loss:1.2992 , Current Loss: 1.3085\n",
      "Steps: 30123 Loss:1.3048 , Current Loss: 1.3799\n",
      "Steps: 30223 Loss:1.3042 , Current Loss: 1.3725\n",
      "Steps: 30323 Loss:1.2978 , Current Loss: 1.3899\n",
      "Steps: 30423 Loss:1.2941 , Current Loss: 1.4015\n",
      "Steps: 30523 Loss:1.3116 , Current Loss: 1.3835\n",
      "Epoch: 9 , Step: 30594 , loss: 1.3078 , Time: 11295.6\n",
      "Model Saved\n",
      "Steps: 30694 Loss:1.3118 , Current Loss: 1.2273\n",
      "Steps: 30794 Loss:1.3078 , Current Loss: 1.3824\n",
      "Steps: 30894 Loss:1.2994 , Current Loss: 1.3795\n",
      "Steps: 30994 Loss:1.2999 , Current Loss: 1.2638\n",
      "Steps: 31094 Loss:1.3000 , Current Loss: 1.2482\n",
      "Steps: 31194 Loss:1.3093 , Current Loss: 1.2626\n",
      "Steps: 31294 Loss:1.2944 , Current Loss: 1.2844\n",
      "Steps: 31394 Loss:1.3060 , Current Loss: 1.3639\n",
      "Steps: 31494 Loss:1.2941 , Current Loss: 1.2218\n",
      "Steps: 31594 Loss:1.2989 , Current Loss: 1.2584\n",
      "Steps: 31694 Loss:1.3014 , Current Loss: 1.3054\n",
      "Steps: 31794 Loss:1.2938 , Current Loss: 1.3865\n",
      "Steps: 31894 Loss:1.2993 , Current Loss: 1.2651\n",
      "Steps: 31994 Loss:1.2888 , Current Loss: 1.3250\n",
      "Steps: 32094 Loss:1.2884 , Current Loss: 1.3352\n",
      "Steps: 32194 Loss:1.2957 , Current Loss: 1.2872\n",
      "Steps: 32294 Loss:1.2896 , Current Loss: 1.2641\n",
      "Epoch: 10 , Step: 32365 , loss: 1.2982 , Time: 11116.1\n",
      "Model Saved\n",
      "Val: F1 Score:57.65 Accuracy:63.80  POS: F1 Score:88.34 Accuracy:94.12 Loss:1.3071 , Time: 2356.9\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32465 Loss:1.3049 , Current Loss: 1.2248\n",
      "Steps: 32565 Loss:1.2873 , Current Loss: 1.2260\n",
      "Steps: 32665 Loss:1.2704 , Current Loss: 1.2502\n",
      "Steps: 32765 Loss:1.2931 , Current Loss: 1.2916\n",
      "Steps: 32865 Loss:1.2917 , Current Loss: 1.2387\n",
      "Steps: 32965 Loss:1.2802 , Current Loss: 1.3496\n",
      "Steps: 33065 Loss:1.2910 , Current Loss: 1.2113\n",
      "Steps: 33165 Loss:1.2964 , Current Loss: 1.3241\n",
      "Steps: 33265 Loss:1.2837 , Current Loss: 1.4260\n",
      "Steps: 33365 Loss:1.2833 , Current Loss: 1.2185\n",
      "Steps: 33465 Loss:1.2998 , Current Loss: 1.1679\n",
      "Steps: 33565 Loss:1.2888 , Current Loss: 1.2011\n",
      "Steps: 33665 Loss:1.2870 , Current Loss: 1.3438\n",
      "Steps: 33765 Loss:1.2976 , Current Loss: 1.3753\n",
      "Steps: 33865 Loss:1.2916 , Current Loss: 1.2826\n",
      "Steps: 33965 Loss:1.2803 , Current Loss: 1.1972\n",
      "Steps: 34065 Loss:1.3049 , Current Loss: 1.3421\n",
      "Epoch: 1 , Step: 34136 , loss: 1.2900 , Time: 10903.5\n",
      "Model Saved\n",
      "Steps: 34236 Loss:1.2772 , Current Loss: 1.3081\n",
      "Steps: 34336 Loss:1.2645 , Current Loss: 1.3174\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 34436 Loss:1.2826 , Current Loss: 1.3203\n",
      "Steps: 34536 Loss:1.2909 , Current Loss: 1.2873\n",
      "Steps: 34636 Loss:1.2842 , Current Loss: 1.2870\n",
      "Steps: 34736 Loss:1.2721 , Current Loss: 1.2659\n",
      "Steps: 34836 Loss:1.2901 , Current Loss: 1.3438\n",
      "Steps: 34936 Loss:1.2827 , Current Loss: 1.2559\n",
      "Steps: 35036 Loss:1.2842 , Current Loss: 1.3157\n",
      "Steps: 35136 Loss:1.2874 , Current Loss: 1.3195\n",
      "Steps: 35236 Loss:1.2878 , Current Loss: 1.2219\n",
      "Steps: 35336 Loss:1.2830 , Current Loss: 1.2379\n",
      "Steps: 35436 Loss:1.2766 , Current Loss: 1.2618\n",
      "Steps: 35536 Loss:1.2784 , Current Loss: 1.3780\n",
      "Steps: 35636 Loss:1.2676 , Current Loss: 1.1421\n",
      "Steps: 35736 Loss:1.2676 , Current Loss: 1.3392\n",
      "Steps: 35836 Loss:1.2822 , Current Loss: 1.2675\n",
      "Steps: 35936 Loss:1.2747 , Current Loss: 1.2895\n",
      "Steps: 36036 Loss:1.2805 , Current Loss: 1.2986\n",
      "Epoch: 1 , Step: 36107 , loss: 1.2805 , Time: 10922.3\n",
      "Model Saved\n",
      "Steps: 36207 Loss:1.2716 , Current Loss: 1.2565\n",
      "Steps: 36307 Loss:1.2795 , Current Loss: 1.2558\n",
      "Steps: 36407 Loss:1.2735 , Current Loss: 1.2126\n",
      "Steps: 36507 Loss:1.2818 , Current Loss: 1.1205\n",
      "Steps: 36607 Loss:1.2787 , Current Loss: 1.3490\n",
      "Steps: 36707 Loss:1.2803 , Current Loss: 1.2825\n",
      "Steps: 36807 Loss:1.2829 , Current Loss: 1.2126\n",
      "Steps: 36907 Loss:1.2737 , Current Loss: 1.3039\n",
      "Steps: 37007 Loss:1.2775 , Current Loss: 1.3703\n",
      "Steps: 37107 Loss:1.2666 , Current Loss: 1.2718\n",
      "Steps: 37207 Loss:1.2716 , Current Loss: 1.3350\n",
      "Steps: 37307 Loss:1.2668 , Current Loss: 1.3507\n",
      "Steps: 37407 Loss:1.2718 , Current Loss: 1.2956\n",
      "Steps: 37507 Loss:1.2766 , Current Loss: 1.3449\n",
      "Steps: 37607 Loss:1.2656 , Current Loss: 1.3037\n",
      "Steps: 37707 Loss:1.2710 , Current Loss: 1.2472\n",
      "Steps: 37807 Loss:1.2551 , Current Loss: 1.1600\n",
      "Epoch: 2 , Step: 37878 , loss: 1.2733 , Time: 10502.8\n",
      "Model Saved\n",
      "Val: F1 Score:58.17 Accuracy:64.39  POS: F1 Score:88.79 Accuracy:94.26 Loss:1.2774 , Time: 2194.9\n",
      "Steps: 37978 Loss:1.2563 , Current Loss: 1.2207\n",
      "Steps: 38078 Loss:1.2733 , Current Loss: 1.1622\n",
      "Steps: 38178 Loss:1.2603 , Current Loss: 1.2621\n",
      "Steps: 38278 Loss:1.2616 , Current Loss: 1.2006\n",
      "Steps: 38378 Loss:1.2738 , Current Loss: 1.2410\n",
      "Steps: 38478 Loss:1.2661 , Current Loss: 1.2718\n",
      "Steps: 38578 Loss:1.2693 , Current Loss: 1.3263\n",
      "Steps: 38678 Loss:1.2726 , Current Loss: 1.3162\n",
      "Steps: 38778 Loss:1.2517 , Current Loss: 1.1444\n",
      "Steps: 38878 Loss:1.2747 , Current Loss: 1.3766\n",
      "Steps: 38978 Loss:1.2596 , Current Loss: 1.4296\n",
      "Steps: 39078 Loss:1.2568 , Current Loss: 1.2184\n",
      "Steps: 39178 Loss:1.2604 , Current Loss: 1.2750\n",
      "Steps: 39278 Loss:1.2716 , Current Loss: 1.2694\n",
      "Steps: 39378 Loss:1.2526 , Current Loss: 1.1793\n",
      "Steps: 39478 Loss:1.2710 , Current Loss: 1.3497\n",
      "Steps: 39578 Loss:1.2615 , Current Loss: 1.1272\n",
      "Epoch: 3 , Step: 39649 , loss: 1.2644 , Time: 10494.0\n",
      "Model Saved\n",
      "Steps: 39749 Loss:1.2571 , Current Loss: 1.2150\n",
      "Steps: 39849 Loss:1.2536 , Current Loss: 1.2461\n",
      "Steps: 39949 Loss:1.2515 , Current Loss: 1.2867\n",
      "Steps: 40049 Loss:1.2638 , Current Loss: 1.3230\n",
      "Steps: 40149 Loss:1.2591 , Current Loss: 1.2031\n",
      "Steps: 40249 Loss:1.2597 , Current Loss: 1.3478\n",
      "Steps: 40349 Loss:1.2550 , Current Loss: 1.1970\n",
      "Steps: 40449 Loss:1.2663 , Current Loss: 1.1961\n",
      "Steps: 40549 Loss:1.2675 , Current Loss: 1.4070\n",
      "Steps: 40649 Loss:1.2514 , Current Loss: 1.1959\n",
      "Steps: 40749 Loss:1.2681 , Current Loss: 1.2284\n",
      "Steps: 40849 Loss:1.2667 , Current Loss: 1.2548\n",
      "Steps: 40949 Loss:1.2611 , Current Loss: 1.1910\n",
      "Steps: 41049 Loss:1.2598 , Current Loss: 1.3715\n",
      "Steps: 41149 Loss:1.2438 , Current Loss: 1.2212\n",
      "Steps: 41249 Loss:1.2607 , Current Loss: 1.3061\n",
      "Steps: 41349 Loss:1.2715 , Current Loss: 1.3657\n",
      "Epoch: 4 , Step: 41420 , loss: 1.2593 , Time: 11448.5\n",
      "Model Saved\n",
      "Val: F1 Score:58.46 Accuracy:64.65  POS: F1 Score:88.85 Accuracy:94.35 Loss:1.2650 , Time: 3913.2\n",
      "Steps: 41520 Loss:1.2559 , Current Loss: 1.3315\n",
      "Steps: 41620 Loss:1.2526 , Current Loss: 1.3458\n",
      "Steps: 41720 Loss:1.2444 , Current Loss: 1.3420\n",
      "Steps: 41820 Loss:1.2539 , Current Loss: 1.1192\n",
      "Steps: 41920 Loss:1.2533 , Current Loss: 1.3530\n",
      "Steps: 42020 Loss:1.2520 , Current Loss: 1.1245\n",
      "Steps: 42120 Loss:1.2556 , Current Loss: 1.2403\n",
      "Steps: 42220 Loss:1.2582 , Current Loss: 1.2643\n",
      "Steps: 42320 Loss:1.2492 , Current Loss: 1.3007\n",
      "Steps: 42420 Loss:1.2332 , Current Loss: 1.1789\n",
      "Steps: 42520 Loss:1.2639 , Current Loss: 1.1920\n",
      "Steps: 42620 Loss:1.2505 , Current Loss: 1.2539\n",
      "Steps: 42720 Loss:1.2510 , Current Loss: 1.1855\n",
      "Steps: 42820 Loss:1.2493 , Current Loss: 1.2990\n",
      "Steps: 42920 Loss:1.2562 , Current Loss: 1.1681\n",
      "Steps: 43020 Loss:1.2573 , Current Loss: 1.2916\n",
      "Steps: 43120 Loss:1.2531 , Current Loss: 1.3417\n",
      "Epoch: 5 , Step: 43191 , loss: 1.2521 , Time: 12138.4\n",
      "Model Saved\n",
      "Steps: 43291 Loss:1.2422 , Current Loss: 1.2130\n",
      "Steps: 43391 Loss:1.2547 , Current Loss: 1.3089\n",
      "Steps: 43491 Loss:1.2281 , Current Loss: 1.1960\n",
      "Steps: 43591 Loss:1.2468 , Current Loss: 1.2522\n",
      "Steps: 43691 Loss:1.2504 , Current Loss: 1.2136\n",
      "Steps: 43791 Loss:1.2499 , Current Loss: 1.2554\n",
      "Steps: 43891 Loss:1.2430 , Current Loss: 1.2358\n",
      "Steps: 43991 Loss:1.2580 , Current Loss: 1.3388\n",
      "Steps: 44091 Loss:1.2378 , Current Loss: 1.3235\n",
      "Steps: 44191 Loss:1.2501 , Current Loss: 1.1776\n",
      "Steps: 44291 Loss:1.2411 , Current Loss: 1.2709\n",
      "Steps: 44391 Loss:1.2454 , Current Loss: 1.2881\n",
      "Steps: 44491 Loss:1.2526 , Current Loss: 1.1560\n",
      "Steps: 44591 Loss:1.2346 , Current Loss: 1.2144\n",
      "Steps: 44691 Loss:1.2462 , Current Loss: 1.2437\n",
      "Steps: 44791 Loss:1.2503 , Current Loss: 1.2598\n",
      "Steps: 44891 Loss:1.2504 , Current Loss: 1.1611\n",
      "Epoch: 6 , Step: 44962 , loss: 1.2460 , Time: 12668.0\n",
      "Model Saved\n",
      "Val: F1 Score:59.04 Accuracy:65.06  POS: F1 Score:88.87 Accuracy:94.37 Loss:1.2564 , Time: 3064.6\n",
      "Steps: 45062 Loss:1.2351 , Current Loss: 1.2954\n",
      "Steps: 45162 Loss:1.2262 , Current Loss: 1.1796\n",
      "Steps: 45262 Loss:1.2397 , Current Loss: 1.2090\n",
      "Steps: 45362 Loss:1.2295 , Current Loss: 1.2274\n",
      "Steps: 45462 Loss:1.2437 , Current Loss: 1.3948\n",
      "Steps: 45562 Loss:1.2440 , Current Loss: 1.3080\n",
      "Steps: 45662 Loss:1.2526 , Current Loss: 1.1452\n",
      "Steps: 45762 Loss:1.2363 , Current Loss: 1.1512\n",
      "Steps: 45862 Loss:1.2426 , Current Loss: 1.1904\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 45962 Loss:1.2408 , Current Loss: 1.2637\n",
      "Steps: 46062 Loss:1.2183 , Current Loss: 1.0508\n",
      "Steps: 46162 Loss:1.2250 , Current Loss: 1.3714\n",
      "Steps: 46262 Loss:1.2178 , Current Loss: 1.3228\n",
      "Steps: 46362 Loss:1.2224 , Current Loss: 1.2397\n",
      "Steps: 46462 Loss:1.2096 , Current Loss: 1.0790\n",
      "Steps: 46562 Loss:1.2142 , Current Loss: 1.1539\n",
      "Steps: 46662 Loss:1.2289 , Current Loss: 1.0988\n",
      "Steps: 46762 Loss:1.2253 , Current Loss: 1.0715\n",
      "Steps: 46862 Loss:1.2199 , Current Loss: 1.1325\n",
      "Steps: 46962 Loss:1.2121 , Current Loss: 1.1962\n",
      "Steps: 47062 Loss:1.2146 , Current Loss: 1.0959\n",
      "Steps: 47162 Loss:1.2176 , Current Loss: 1.0890\n",
      "Steps: 47262 Loss:1.2186 , Current Loss: 1.1713\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 47362 Loss:1.2001 , Current Loss: 1.1903\n",
      "Steps: 47462 Loss:1.2224 , Current Loss: 1.1058\n",
      "Steps: 47562 Loss:1.2119 , Current Loss: 1.2138\n",
      "Steps: 47662 Loss:1.2174 , Current Loss: 1.2613\n",
      "Steps: 47762 Loss:1.2113 , Current Loss: 1.1965\n",
      "Steps: 47862 Loss:1.2086 , Current Loss: 1.0919\n",
      "Steps: 47962 Loss:1.2051 , Current Loss: 1.2413\n",
      "Steps: 48062 Loss:1.2059 , Current Loss: 1.2251\n",
      "Steps: 48162 Loss:1.2126 , Current Loss: 1.1006\n",
      "Steps: 48262 Loss:1.2056 , Current Loss: 1.2067\n",
      "Steps: 48362 Loss:1.2115 , Current Loss: 1.1876\n",
      "Steps: 48462 Loss:1.2202 , Current Loss: 1.1297\n",
      "Steps: 48562 Loss:1.2222 , Current Loss: 1.2417\n",
      "Steps: 48662 Loss:1.2038 , Current Loss: 1.1763\n",
      "Steps: 48762 Loss:1.2122 , Current Loss: 1.1915\n",
      "Steps: 48862 Loss:1.1997 , Current Loss: 1.2488\n",
      "Steps: 48962 Loss:1.2198 , Current Loss: 1.2170\n",
      "Epoch: 1 , Step: 49033 , loss: 1.2112 , Time: 10694.7\n",
      "Model Saved\n",
      "Steps: 49133 Loss:1.2012 , Current Loss: 1.1703\n",
      "Steps: 49233 Loss:1.1981 , Current Loss: 1.2066\n",
      "Steps: 49333 Loss:1.1909 , Current Loss: 1.0049\n",
      "Steps: 49433 Loss:1.1889 , Current Loss: 1.3052\n",
      "Steps: 49533 Loss:1.2079 , Current Loss: 1.1101\n",
      "Steps: 49633 Loss:1.2083 , Current Loss: 1.3005\n",
      "Steps: 49733 Loss:1.2069 , Current Loss: 1.2828\n",
      "Steps: 49833 Loss:1.1960 , Current Loss: 1.1774\n",
      "Steps: 49933 Loss:1.2134 , Current Loss: 1.3404\n",
      "Steps: 50033 Loss:1.2114 , Current Loss: 1.0950\n",
      "Steps: 50133 Loss:1.2024 , Current Loss: 1.2568\n",
      "Steps: 50233 Loss:1.1940 , Current Loss: 1.1099\n",
      "Steps: 50333 Loss:1.2068 , Current Loss: 1.3313\n",
      "Steps: 50433 Loss:1.1895 , Current Loss: 1.1642\n",
      "Steps: 50533 Loss:1.1982 , Current Loss: 1.1361\n",
      "Steps: 50633 Loss:1.1968 , Current Loss: 1.1478\n",
      "Steps: 50733 Loss:1.2052 , Current Loss: 1.1667\n",
      "Epoch: 2 , Step: 50804 , loss: 1.2006 , Time: 10587.9\n",
      "Model Saved\n",
      "Val: F1 Score:60.25 Accuracy:66.14  POS: F1 Score:89.15 Accuracy:94.57 Loss:1.2132 , Time: 2243.9\n",
      "Steps: 50904 Loss:1.1958 , Current Loss: 1.2132\n",
      "Steps: 51004 Loss:1.2078 , Current Loss: 1.3088\n",
      "Steps: 51104 Loss:1.2027 , Current Loss: 1.0479\n",
      "Steps: 51204 Loss:1.1894 , Current Loss: 1.2968\n",
      "Steps: 51304 Loss:1.1960 , Current Loss: 1.1726\n",
      "Steps: 51404 Loss:1.1828 , Current Loss: 1.3252\n",
      "Steps: 51504 Loss:1.2008 , Current Loss: 1.4271\n",
      "Steps: 51604 Loss:1.2073 , Current Loss: 1.1642\n",
      "Steps: 51704 Loss:1.1924 , Current Loss: 1.2969\n",
      "Steps: 51804 Loss:1.2112 , Current Loss: 1.3283\n",
      "Steps: 51904 Loss:1.1955 , Current Loss: 1.1913\n",
      "Steps: 52004 Loss:1.1767 , Current Loss: 1.2810\n",
      "Steps: 52104 Loss:1.1973 , Current Loss: 1.3049\n",
      "Steps: 52204 Loss:1.1808 , Current Loss: 1.2284\n",
      "Steps: 52304 Loss:1.1888 , Current Loss: 1.3599\n",
      "Steps: 52404 Loss:1.1874 , Current Loss: 1.1548\n",
      "Steps: 52504 Loss:1.2039 , Current Loss: 1.1368\n",
      "Epoch: 3 , Step: 52575 , loss: 1.1950 , Time: 10597.4\n",
      "Model Saved\n",
      "Steps: 52675 Loss:1.1814 , Current Loss: 1.2166\n",
      "Steps: 52775 Loss:1.1864 , Current Loss: 1.2148\n",
      "Steps: 52875 Loss:1.1894 , Current Loss: 1.2851\n",
      "Steps: 52975 Loss:1.1864 , Current Loss: 1.1717\n",
      "Steps: 53075 Loss:1.1959 , Current Loss: 1.2047\n",
      "Steps: 53175 Loss:1.1882 , Current Loss: 1.2360\n",
      "Steps: 53275 Loss:1.1873 , Current Loss: 1.1281\n",
      "Steps: 53375 Loss:1.1923 , Current Loss: 1.1783\n",
      "Steps: 53475 Loss:1.1912 , Current Loss: 1.1718\n",
      "Steps: 53575 Loss:1.1827 , Current Loss: 1.2343\n",
      "Steps: 53675 Loss:1.1868 , Current Loss: 1.1751\n",
      "Steps: 53775 Loss:1.1866 , Current Loss: 1.1590\n",
      "Steps: 53875 Loss:1.1947 , Current Loss: 1.2580\n",
      "Steps: 53975 Loss:1.1901 , Current Loss: 1.1714\n",
      "Steps: 54075 Loss:1.1915 , Current Loss: 1.0946\n",
      "Steps: 54175 Loss:1.1997 , Current Loss: 1.1374\n",
      "Steps: 54275 Loss:1.1925 , Current Loss: 1.2196\n",
      "Epoch: 4 , Step: 54346 , loss: 1.1896 , Time: 10611.0\n",
      "Model Saved\n",
      "Val: F1 Score:60.69 Accuracy:66.42  POS: F1 Score:89.36 Accuracy:94.61 Loss:1.2007 , Time: 2228.0\n",
      "Steps: 54446 Loss:1.1974 , Current Loss: 1.1799\n",
      "Steps: 54546 Loss:1.1865 , Current Loss: 1.2912\n",
      "Steps: 54646 Loss:1.1904 , Current Loss: 1.1529\n",
      "Steps: 54746 Loss:1.1881 , Current Loss: 1.0636\n",
      "Steps: 54846 Loss:1.1722 , Current Loss: 1.1382\n",
      "Steps: 54946 Loss:1.1887 , Current Loss: 1.2698\n",
      "Steps: 55046 Loss:1.1846 , Current Loss: 1.1999\n",
      "Steps: 55146 Loss:1.1851 , Current Loss: 1.1662\n",
      "Steps: 55246 Loss:1.1816 , Current Loss: 1.1226\n",
      "Steps: 55346 Loss:1.1760 , Current Loss: 1.2202\n",
      "Steps: 55446 Loss:1.1846 , Current Loss: 1.2463\n",
      "Steps: 55546 Loss:1.1861 , Current Loss: 1.1945\n",
      "Steps: 55646 Loss:1.1973 , Current Loss: 1.0901\n",
      "Steps: 55746 Loss:1.1951 , Current Loss: 1.1942\n",
      "Steps: 55846 Loss:1.1784 , Current Loss: 1.2049\n",
      "Steps: 55946 Loss:1.1740 , Current Loss: 1.2292\n",
      "Steps: 56046 Loss:1.1798 , Current Loss: 1.1953\n",
      "Epoch: 5 , Step: 56117 , loss: 1.1851 , Time: 10601.7\n",
      "Model Saved\n",
      "Steps: 56217 Loss:1.1709 , Current Loss: 1.1491\n",
      "Steps: 56317 Loss:1.1825 , Current Loss: 1.1054\n",
      "Steps: 56417 Loss:1.1901 , Current Loss: 1.1720\n",
      "Steps: 56517 Loss:1.1817 , Current Loss: 1.1009\n",
      "Steps: 56617 Loss:1.1694 , Current Loss: 1.0515\n",
      "Steps: 56717 Loss:1.1724 , Current Loss: 1.0883\n",
      "Steps: 56817 Loss:1.1821 , Current Loss: 1.0992\n",
      "Steps: 56917 Loss:1.1820 , Current Loss: 1.2422\n",
      "Steps: 57017 Loss:1.1790 , Current Loss: 1.1861\n",
      "Steps: 57117 Loss:1.1714 , Current Loss: 1.1549\n",
      "Steps: 57217 Loss:1.1678 , Current Loss: 1.2045\n",
      "Steps: 57317 Loss:1.1722 , Current Loss: 1.1069\n",
      "Steps: 57417 Loss:1.1842 , Current Loss: 1.1532\n",
      "Steps: 57517 Loss:1.1782 , Current Loss: 1.2256\n",
      "Steps: 57617 Loss:1.1820 , Current Loss: 1.1728\n",
      "Steps: 57717 Loss:1.1830 , Current Loss: 1.0897\n",
      "Steps: 57817 Loss:1.1795 , Current Loss: 1.2234\n",
      "Epoch: 6 , Step: 57888 , loss: 1.1780 , Time: 10621.9\n",
      "Model Saved\n",
      "Val: F1 Score:61.17 Accuracy:66.71  POS: F1 Score:89.56 Accuracy:94.66 Loss:1.1916 , Time: 2232.2\n",
      "Steps: 57988 Loss:1.1647 , Current Loss: 1.1045\n",
      "Steps: 58088 Loss:1.1822 , Current Loss: 1.2537\n",
      "Steps: 58188 Loss:1.1792 , Current Loss: 1.1303\n",
      "Steps: 58288 Loss:1.1846 , Current Loss: 1.1964\n",
      "Steps: 58388 Loss:1.1742 , Current Loss: 1.1325\n",
      "Steps: 58488 Loss:1.1845 , Current Loss: 1.2433\n",
      "Steps: 58588 Loss:1.1788 , Current Loss: 0.9863\n",
      "Steps: 58688 Loss:1.1730 , Current Loss: 0.9882\n",
      "Steps: 58788 Loss:1.1718 , Current Loss: 1.1535\n",
      "Steps: 58888 Loss:1.1598 , Current Loss: 1.1080\n",
      "Steps: 58988 Loss:1.1704 , Current Loss: 1.1279\n",
      "Steps: 59088 Loss:1.1633 , Current Loss: 1.1222\n",
      "Steps: 59188 Loss:1.1650 , Current Loss: 1.0996\n",
      "Steps: 59288 Loss:1.1777 , Current Loss: 1.1796\n",
      "Steps: 59388 Loss:1.1793 , Current Loss: 1.2044\n",
      "Steps: 59488 Loss:1.1680 , Current Loss: 1.1774\n",
      "Steps: 59588 Loss:1.1701 , Current Loss: 1.0241\n",
      "Epoch: 7 , Step: 59659 , loss: 1.1734 , Time: 10595.7\n",
      "Model Saved\n",
      "Steps: 59759 Loss:1.1721 , Current Loss: 1.0910\n",
      "Steps: 59859 Loss:1.1782 , Current Loss: 1.1412\n",
      "Steps: 59959 Loss:1.1708 , Current Loss: 1.1047\n",
      "Steps: 60059 Loss:1.1705 , Current Loss: 1.2008\n",
      "Steps: 60159 Loss:1.1699 , Current Loss: 0.9897\n",
      "Steps: 60259 Loss:1.1664 , Current Loss: 1.1826\n",
      "Steps: 60359 Loss:1.1773 , Current Loss: 1.1586\n",
      "Steps: 60459 Loss:1.1658 , Current Loss: 1.1127\n",
      "Steps: 60559 Loss:1.1821 , Current Loss: 1.2275\n",
      "Steps: 60659 Loss:1.1687 , Current Loss: 1.2605\n",
      "Steps: 60759 Loss:1.1762 , Current Loss: 1.2631\n",
      "Steps: 60859 Loss:1.1696 , Current Loss: 1.0799\n",
      "Steps: 60959 Loss:1.1641 , Current Loss: 1.2366\n",
      "Steps: 61059 Loss:1.1775 , Current Loss: 1.2296\n",
      "Steps: 61159 Loss:1.1728 , Current Loss: 1.2448\n",
      "Steps: 61259 Loss:1.1607 , Current Loss: 1.2623\n",
      "Steps: 61359 Loss:1.1651 , Current Loss: 1.1214\n",
      "Epoch: 8 , Step: 61430 , loss: 1.1704 , Time: 10614.2\n",
      "Model Saved\n",
      "Val: F1 Score:61.03 Accuracy:66.76  POS: F1 Score:89.61 Accuracy:94.71 Loss:1.1828 , Time: 2232.2\n",
      "Steps: 61530 Loss:1.1644 , Current Loss: 1.1744\n",
      "Steps: 61630 Loss:1.1757 , Current Loss: 1.1361\n",
      "Steps: 61730 Loss:1.1690 , Current Loss: 1.1632\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 61830 Loss:1.1579 , Current Loss: 1.0321\n",
      "Steps: 61930 Loss:1.1521 , Current Loss: 1.1229\n",
      "Steps: 62030 Loss:1.1666 , Current Loss: 1.2002\n",
      "Steps: 62130 Loss:1.1534 , Current Loss: 1.1285\n",
      "Steps: 62230 Loss:1.1583 , Current Loss: 1.0084\n",
      "Steps: 62330 Loss:1.1593 , Current Loss: 1.0921\n",
      "Steps: 62430 Loss:1.1541 , Current Loss: 1.1498\n",
      "Steps: 62530 Loss:1.1484 , Current Loss: 1.1735\n",
      "Steps: 62630 Loss:1.1605 , Current Loss: 1.1531\n",
      "Steps: 62730 Loss:1.1446 , Current Loss: 1.1768\n",
      "Steps: 62830 Loss:1.1490 , Current Loss: 1.2653\n",
      "Steps: 62930 Loss:1.1532 , Current Loss: 1.1785\n",
      "Steps: 63030 Loss:1.1510 , Current Loss: 1.0946\n",
      "Steps: 63130 Loss:1.1483 , Current Loss: 1.1987\n",
      "Steps: 63230 Loss:1.1545 , Current Loss: 1.0606\n",
      "Steps: 63330 Loss:1.1536 , Current Loss: 1.2039\n",
      "Steps: 63430 Loss:1.1545 , Current Loss: 1.1147\n",
      "Epoch: 1 , Step: 63501 , loss: 1.1533 , Time: 10642.6\n",
      "Model Saved\n",
      "Steps: 63601 Loss:1.1432 , Current Loss: 1.1006\n",
      "Steps: 63701 Loss:1.1529 , Current Loss: 1.2350\n",
      "Steps: 63801 Loss:1.1488 , Current Loss: 1.1479\n",
      "Steps: 63901 Loss:1.1387 , Current Loss: 1.2009\n",
      "Steps: 64001 Loss:1.1449 , Current Loss: 1.1136\n",
      "Steps: 64101 Loss:1.1434 , Current Loss: 1.1414\n",
      "Steps: 64201 Loss:1.1474 , Current Loss: 1.2535\n",
      "Steps: 64301 Loss:1.1482 , Current Loss: 1.3167\n",
      "Steps: 64401 Loss:1.1438 , Current Loss: 1.0537\n",
      "Steps: 64501 Loss:1.1486 , Current Loss: 1.1130\n",
      "Steps: 64601 Loss:1.1464 , Current Loss: 1.2359\n",
      "Steps: 64701 Loss:1.1492 , Current Loss: 1.1490\n",
      "Steps: 64801 Loss:1.1367 , Current Loss: 1.1168\n",
      "Steps: 64901 Loss:1.1552 , Current Loss: 1.2031\n",
      "Steps: 65001 Loss:1.1412 , Current Loss: 1.0709\n",
      "Steps: 65101 Loss:1.1395 , Current Loss: 1.2485\n",
      "Steps: 65201 Loss:1.1459 , Current Loss: 1.1663\n",
      "Epoch: 2 , Step: 65272 , loss: 1.1450 , Time: 10691.1\n",
      "Model Saved\n",
      "Val: F1 Score:61.95 Accuracy:67.41  POS: F1 Score:89.78 Accuracy:94.80 Loss:1.1555 , Time: 2255.2\n",
      "Steps: 65372 Loss:1.1385 , Current Loss: 1.1447\n",
      "Steps: 65472 Loss:1.1310 , Current Loss: 1.1989\n",
      "Steps: 65572 Loss:1.1358 , Current Loss: 1.1093\n",
      "Steps: 65672 Loss:1.1454 , Current Loss: 1.2123\n",
      "Steps: 65772 Loss:1.1341 , Current Loss: 1.0525\n",
      "Steps: 65872 Loss:1.1415 , Current Loss: 1.2802\n",
      "Steps: 65972 Loss:1.1327 , Current Loss: 1.0392\n",
      "Steps: 66072 Loss:1.1423 , Current Loss: 1.2417\n",
      "Steps: 66172 Loss:1.1374 , Current Loss: 1.1742\n",
      "Steps: 66272 Loss:1.1388 , Current Loss: 1.1474\n",
      "Steps: 66372 Loss:1.1437 , Current Loss: 1.2585\n",
      "Steps: 66472 Loss:1.1350 , Current Loss: 1.2094\n",
      "Steps: 66572 Loss:1.1349 , Current Loss: 1.0855\n",
      "Steps: 66672 Loss:1.1419 , Current Loss: 1.1704\n",
      "Steps: 66772 Loss:1.1357 , Current Loss: 1.0606\n",
      "Steps: 66872 Loss:1.1351 , Current Loss: 1.0922\n",
      "Steps: 66972 Loss:1.1425 , Current Loss: 1.0866\n",
      "Epoch: 3 , Step: 67043 , loss: 1.1379 , Time: 10693.1\n",
      "Model Saved\n",
      "Steps: 67143 Loss:1.1491 , Current Loss: 1.1634\n",
      "Steps: 67243 Loss:1.1449 , Current Loss: 1.1835\n",
      "Steps: 67343 Loss:1.1449 , Current Loss: 1.1064\n",
      "Steps: 67443 Loss:1.1250 , Current Loss: 1.1272\n",
      "Steps: 67543 Loss:1.1330 , Current Loss: 1.0985\n",
      "Steps: 67643 Loss:1.1392 , Current Loss: 1.2205\n",
      "Steps: 67743 Loss:1.1363 , Current Loss: 1.2373\n",
      "Steps: 67843 Loss:1.1297 , Current Loss: 1.1329\n",
      "Steps: 67943 Loss:1.1380 , Current Loss: 1.0193\n",
      "Steps: 68043 Loss:1.1363 , Current Loss: 1.1574\n",
      "Steps: 68143 Loss:1.1237 , Current Loss: 1.0878\n",
      "Steps: 68243 Loss:1.1397 , Current Loss: 1.2177\n",
      "Steps: 68343 Loss:1.1169 , Current Loss: 1.0973\n",
      "Steps: 68443 Loss:1.1310 , Current Loss: 1.1425\n",
      "Steps: 68543 Loss:1.1284 , Current Loss: 1.1763\n",
      "Steps: 68643 Loss:1.1393 , Current Loss: 1.1089\n",
      "Steps: 68743 Loss:1.1353 , Current Loss: 1.1626\n",
      "Epoch: 4 , Step: 68814 , loss: 1.1349 , Time: 10818.4\n",
      "Model Saved\n",
      "Val: F1 Score:62.10 Accuracy:67.67  POS: F1 Score:89.86 Accuracy:94.85 Loss:1.1425 , Time: 2230.0\n",
      "Steps: 68914 Loss:1.1295 , Current Loss: 1.0950\n",
      "Steps: 69014 Loss:1.1369 , Current Loss: 1.1061\n",
      "Steps: 69114 Loss:1.1344 , Current Loss: 1.0613\n",
      "Steps: 69214 Loss:1.1252 , Current Loss: 1.2243\n",
      "Steps: 69314 Loss:1.1333 , Current Loss: 1.1477\n",
      "Steps: 69414 Loss:1.1245 , Current Loss: 1.1246\n",
      "Steps: 69514 Loss:1.1381 , Current Loss: 1.0944\n",
      "Steps: 69614 Loss:1.1196 , Current Loss: 1.1225\n",
      "Steps: 69714 Loss:1.1337 , Current Loss: 0.9902\n",
      "Steps: 69814 Loss:1.1185 , Current Loss: 1.2190\n",
      "Steps: 69914 Loss:1.1225 , Current Loss: 1.0359\n",
      "Steps: 70014 Loss:1.1228 , Current Loss: 1.0526\n",
      "Steps: 70114 Loss:1.1352 , Current Loss: 1.0490\n",
      "Steps: 70214 Loss:1.1364 , Current Loss: 0.9841\n",
      "Steps: 70314 Loss:1.1264 , Current Loss: 1.1530\n",
      "Steps: 70414 Loss:1.1235 , Current Loss: 1.2257\n",
      "Steps: 70514 Loss:1.1315 , Current Loss: 1.2252\n",
      "Epoch: 5 , Step: 70585 , loss: 1.1294 , Time: 10592.5\n",
      "Model Saved\n",
      "Steps: 70685 Loss:1.1315 , Current Loss: 1.1827\n",
      "Steps: 70785 Loss:1.1344 , Current Loss: 1.1101\n",
      "Steps: 70885 Loss:1.1127 , Current Loss: 1.1238\n",
      "Steps: 70985 Loss:1.1330 , Current Loss: 1.0233\n",
      "Steps: 71085 Loss:1.1342 , Current Loss: 1.1001\n",
      "Steps: 71185 Loss:1.1122 , Current Loss: 1.2205\n",
      "Steps: 71285 Loss:1.1269 , Current Loss: 1.1645\n",
      "Steps: 71385 Loss:1.1222 , Current Loss: 1.1710\n",
      "Steps: 71485 Loss:1.1337 , Current Loss: 1.1484\n",
      "Steps: 71585 Loss:1.1235 , Current Loss: 1.3672\n",
      "Steps: 71685 Loss:1.1350 , Current Loss: 1.2091\n",
      "Steps: 71785 Loss:1.1191 , Current Loss: 1.1509\n",
      "Steps: 71885 Loss:1.1304 , Current Loss: 1.0907\n",
      "Steps: 71985 Loss:1.1422 , Current Loss: 1.1453\n",
      "Steps: 72085 Loss:1.1254 , Current Loss: 0.9949\n",
      "Steps: 72185 Loss:1.1358 , Current Loss: 1.0892\n",
      "Steps: 72285 Loss:1.1137 , Current Loss: 1.1872\n",
      "Epoch: 6 , Step: 72356 , loss: 1.1282 , Time: 10675.6\n",
      "Model Saved\n",
      "Val: F1 Score:62.25 Accuracy:67.73  POS: F1 Score:89.88 Accuracy:94.89 Loss:1.1409 , Time: 2275.4\n",
      "Steps: 72456 Loss:1.1325 , Current Loss: 1.2194\n",
      "Steps: 72556 Loss:1.1226 , Current Loss: 1.1166\n",
      "Steps: 72656 Loss:1.1310 , Current Loss: 1.1967\n",
      "Steps: 72756 Loss:1.1309 , Current Loss: 1.1229\n",
      "Steps: 72856 Loss:1.1322 , Current Loss: 1.1153\n",
      "Steps: 72956 Loss:1.1304 , Current Loss: 1.0738\n",
      "Steps: 73056 Loss:1.1046 , Current Loss: 0.9820\n",
      "Steps: 73156 Loss:1.1223 , Current Loss: 1.2578\n",
      "Steps: 73256 Loss:1.1272 , Current Loss: 1.0811\n",
      "Steps: 73356 Loss:1.1201 , Current Loss: 1.1046\n",
      "Steps: 73456 Loss:1.1258 , Current Loss: 1.0749\n",
      "Steps: 73556 Loss:1.1223 , Current Loss: 1.2254\n",
      "Steps: 73656 Loss:1.1274 , Current Loss: 1.1229\n",
      "Steps: 73756 Loss:1.1291 , Current Loss: 1.1855\n",
      "Steps: 73856 Loss:1.1262 , Current Loss: 1.1581\n",
      "Steps: 73956 Loss:1.1096 , Current Loss: 1.1171\n",
      "Steps: 74056 Loss:1.1263 , Current Loss: 1.2053\n",
      "Epoch: 7 , Step: 74127 , loss: 1.1250 , Time: 10683.7\n",
      "Model Saved\n",
      "Steps: 74227 Loss:1.1170 , Current Loss: 1.1663\n",
      "Steps: 74327 Loss:1.1318 , Current Loss: 1.2652\n",
      "Steps: 74427 Loss:1.1185 , Current Loss: 1.1942\n",
      "Steps: 74527 Loss:1.1320 , Current Loss: 1.1360\n",
      "Steps: 74627 Loss:1.1261 , Current Loss: 1.2278\n",
      "Steps: 74727 Loss:1.1124 , Current Loss: 1.0389\n",
      "Steps: 74827 Loss:1.1148 , Current Loss: 1.0621\n",
      "Steps: 74927 Loss:1.1172 , Current Loss: 0.9816\n",
      "Steps: 75027 Loss:1.1161 , Current Loss: 1.0212\n",
      "Steps: 75127 Loss:1.1220 , Current Loss: 1.0718\n",
      "Steps: 75227 Loss:1.1092 , Current Loss: 1.1159\n",
      "Steps: 75327 Loss:1.1206 , Current Loss: 1.1928\n",
      "Steps: 75427 Loss:1.1213 , Current Loss: 1.0172\n",
      "Steps: 75527 Loss:1.1188 , Current Loss: 1.0896\n",
      "Steps: 75627 Loss:1.1164 , Current Loss: 1.0541\n",
      "Steps: 75727 Loss:1.1213 , Current Loss: 1.1360\n",
      "Steps: 75827 Loss:1.1261 , Current Loss: 1.0524\n",
      "Epoch: 8 , Step: 75898 , loss: 1.1198 , Time: 11161.5\n",
      "Model Saved\n",
      "Val: F1 Score:62.84 Accuracy:68.12  POS: F1 Score:90.04 Accuracy:94.92 Loss:1.1308 , Time: 2350.0\n",
      "Steps: 75998 Loss:1.1238 , Current Loss: 1.1597\n",
      "Steps: 76098 Loss:1.1144 , Current Loss: 1.1309\n",
      "Steps: 76198 Loss:1.1138 , Current Loss: 1.2035\n",
      "Steps: 76298 Loss:1.1281 , Current Loss: 1.1918\n",
      "Steps: 76398 Loss:1.1235 , Current Loss: 1.4066\n",
      "Steps: 76498 Loss:1.1165 , Current Loss: 1.1323\n",
      "Steps: 76598 Loss:1.1171 , Current Loss: 1.0966\n",
      "Steps: 76698 Loss:1.1177 , Current Loss: 1.0403\n",
      "Steps: 76798 Loss:1.1130 , Current Loss: 1.2111\n",
      "Steps: 76898 Loss:1.1181 , Current Loss: 1.0470\n",
      "Steps: 76998 Loss:1.1275 , Current Loss: 1.1965\n",
      "Steps: 77098 Loss:1.1198 , Current Loss: 1.1767\n",
      "Steps: 77198 Loss:1.1229 , Current Loss: 1.2053\n",
      "Steps: 77298 Loss:1.1256 , Current Loss: 1.2060\n",
      "Steps: 77398 Loss:1.1124 , Current Loss: 1.1210\n",
      "Steps: 77498 Loss:1.1221 , Current Loss: 1.2273\n",
      "Steps: 77598 Loss:1.1265 , Current Loss: 1.0368\n",
      "Epoch: 9 , Step: 77669 , loss: 1.1206 , Time: 10954.1\n",
      "Model Saved\n",
      "Steps: 77769 Loss:1.1182 , Current Loss: 1.0866\n",
      "Steps: 77869 Loss:1.1226 , Current Loss: 1.0535\n",
      "Steps: 77969 Loss:1.1226 , Current Loss: 1.1189\n",
      "Steps: 78069 Loss:1.1125 , Current Loss: 1.0898\n",
      "Steps: 78169 Loss:1.1133 , Current Loss: 1.1330\n",
      "Steps: 78269 Loss:1.1144 , Current Loss: 1.0612\n",
      "Steps: 78369 Loss:1.1167 , Current Loss: 1.1368\n",
      "Steps: 78469 Loss:1.1066 , Current Loss: 1.1335\n",
      "Steps: 78569 Loss:1.1179 , Current Loss: 1.0335\n",
      "Steps: 78669 Loss:1.1180 , Current Loss: 1.1131\n",
      "Steps: 78769 Loss:1.1181 , Current Loss: 1.0929\n",
      "Steps: 78869 Loss:1.1251 , Current Loss: 1.0491\n",
      "Steps: 78969 Loss:1.1160 , Current Loss: 0.9790\n",
      "Steps: 79069 Loss:1.1148 , Current Loss: 1.1314\n",
      "Steps: 79169 Loss:1.1185 , Current Loss: 1.2695\n",
      "Steps: 79269 Loss:1.1138 , Current Loss: 1.0725\n",
      "Steps: 79369 Loss:1.1207 , Current Loss: 1.1797\n",
      "Epoch: 10 , Step: 79440 , loss: 1.1164 , Time: 10607.4\n",
      "Model Saved\n",
      "Val: F1 Score:62.92 Accuracy:68.19  POS: F1 Score:89.98 Accuracy:94.93 Loss:1.1207 , Time: 2234.3\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 79540 Loss:1.1178 , Current Loss: 1.2695\n",
      "Steps: 79640 Loss:1.1092 , Current Loss: 1.0448\n",
      "Steps: 79740 Loss:1.1106 , Current Loss: 1.1329\n",
      "Steps: 79840 Loss:1.1163 , Current Loss: 1.0621\n",
      "Steps: 79940 Loss:1.1007 , Current Loss: 1.0109\n",
      "Steps: 80040 Loss:1.1170 , Current Loss: 1.0699\n",
      "Steps: 80140 Loss:1.1124 , Current Loss: 1.0198\n",
      "Steps: 80240 Loss:1.1125 , Current Loss: 1.0548\n",
      "Steps: 80340 Loss:1.0992 , Current Loss: 1.1341\n",
      "Steps: 80440 Loss:1.1191 , Current Loss: 1.0745\n",
      "Steps: 80540 Loss:1.1051 , Current Loss: 1.0424\n",
      "Steps: 80640 Loss:1.1212 , Current Loss: 1.3158\n",
      "Steps: 80740 Loss:1.1037 , Current Loss: 1.1604\n",
      "Steps: 80840 Loss:1.1198 , Current Loss: 1.2913\n",
      "Steps: 80940 Loss:1.1110 , Current Loss: 1.1918\n",
      "Steps: 81040 Loss:1.1207 , Current Loss: 1.0651\n",
      "Steps: 81140 Loss:1.1172 , Current Loss: 1.1293\n",
      "Epoch: 1 , Step: 81211 , loss: 1.1127 , Time: 10584.8\n",
      "Model Saved\n",
      "Steps: 81311 Loss:1.1207 , Current Loss: 1.0546\n",
      "Steps: 81411 Loss:1.1127 , Current Loss: 1.0906\n",
      "Steps: 81511 Loss:1.1165 , Current Loss: 1.0438\n",
      "Steps: 81611 Loss:1.1094 , Current Loss: 1.0608\n",
      "Steps: 81711 Loss:1.1083 , Current Loss: 1.2219\n",
      "Steps: 81811 Loss:1.1018 , Current Loss: 1.1028\n",
      "Steps: 81911 Loss:1.1054 , Current Loss: 1.0602\n",
      "Steps: 82011 Loss:1.1148 , Current Loss: 1.1135\n",
      "Steps: 82111 Loss:1.1044 , Current Loss: 1.0180\n",
      "Steps: 82211 Loss:1.1106 , Current Loss: 1.1097\n",
      "Steps: 82311 Loss:1.1141 , Current Loss: 1.0878\n",
      "Steps: 82411 Loss:1.1153 , Current Loss: 1.0604\n",
      "Steps: 82511 Loss:1.1135 , Current Loss: 1.1056\n",
      "Steps: 82611 Loss:1.1118 , Current Loss: 1.0840\n",
      "Steps: 82711 Loss:1.1146 , Current Loss: 0.9120\n",
      "Steps: 82811 Loss:1.1079 , Current Loss: 1.0114\n",
      "Steps: 82911 Loss:1.1189 , Current Loss: 1.1481\n",
      "Epoch: 2 , Step: 82982 , loss: 1.1119 , Time: 10612.1\n",
      "Model Saved\n",
      "Val: F1 Score:62.89 Accuracy:68.19  POS: F1 Score:89.99 Accuracy:94.95 Loss:1.1223 , Time: 2236.0\n",
      "Steps: 83082 Loss:1.1117 , Current Loss: 1.1563\n",
      "Steps: 83182 Loss:1.1046 , Current Loss: 1.0305\n",
      "Steps: 83282 Loss:1.0981 , Current Loss: 1.0602\n",
      "Steps: 83382 Loss:1.1101 , Current Loss: 1.0685\n",
      "Steps: 83482 Loss:1.1183 , Current Loss: 1.1592\n",
      "Steps: 83582 Loss:1.1181 , Current Loss: 1.0787\n",
      "Steps: 83682 Loss:1.1100 , Current Loss: 1.0549\n",
      "Steps: 83782 Loss:1.1162 , Current Loss: 1.1977\n",
      "Steps: 83882 Loss:1.1104 , Current Loss: 1.0912\n",
      "Steps: 83982 Loss:1.1098 , Current Loss: 1.1265\n",
      "Steps: 84082 Loss:1.1184 , Current Loss: 1.0471\n",
      "Steps: 84182 Loss:1.1077 , Current Loss: 1.1521\n",
      "Steps: 84282 Loss:1.1055 , Current Loss: 1.0722\n",
      "Steps: 84382 Loss:1.1081 , Current Loss: 1.2035\n",
      "Steps: 84482 Loss:1.1105 , Current Loss: 1.1061\n",
      "Steps: 84582 Loss:1.1161 , Current Loss: 1.1316\n",
      "Steps: 84682 Loss:1.1026 , Current Loss: 1.1627\n",
      "Epoch: 3 , Step: 84753 , loss: 1.1101 , Time: 10664.9\n",
      "Model Saved\n",
      "Steps: 84853 Loss:1.0982 , Current Loss: 1.0513\n",
      "Steps: 84953 Loss:1.0994 , Current Loss: 1.0964\n",
      "Steps: 85053 Loss:1.1075 , Current Loss: 1.0417\n",
      "Steps: 85153 Loss:1.1010 , Current Loss: 1.0628\n",
      "Steps: 85253 Loss:1.0983 , Current Loss: 1.1824\n",
      "Steps: 85353 Loss:1.1172 , Current Loss: 1.1781\n",
      "Steps: 85453 Loss:1.1061 , Current Loss: 1.1755\n",
      "Steps: 85553 Loss:1.1227 , Current Loss: 1.1656\n",
      "Steps: 85653 Loss:1.1032 , Current Loss: 1.1693\n",
      "Steps: 85753 Loss:1.1052 , Current Loss: 1.1241\n",
      "Steps: 85853 Loss:1.1014 , Current Loss: 1.0490\n",
      "Steps: 85953 Loss:1.1002 , Current Loss: 1.0861\n",
      "Steps: 86053 Loss:1.1195 , Current Loss: 1.0808\n",
      "Steps: 86153 Loss:1.1110 , Current Loss: 1.2061\n",
      "Steps: 86253 Loss:1.1025 , Current Loss: 1.1602\n",
      "Steps: 86353 Loss:1.1163 , Current Loss: 1.0959\n",
      "Steps: 86453 Loss:1.1067 , Current Loss: 0.9891\n",
      "Epoch: 4 , Step: 86524 , loss: 1.1073 , Time: 10821.2\n",
      "Model Saved\n",
      "Val: F1 Score:62.86 Accuracy:68.38  POS: F1 Score:90.16 Accuracy:94.97 Loss:1.1173 , Time: 2273.3\n",
      "Steps: 86624 Loss:1.1022 , Current Loss: 1.1279\n",
      "Steps: 86724 Loss:1.1122 , Current Loss: 1.1560\n",
      "Steps: 86824 Loss:1.1091 , Current Loss: 1.0193\n",
      "Steps: 86924 Loss:1.1116 , Current Loss: 1.0206\n",
      "Steps: 87024 Loss:1.1106 , Current Loss: 1.1130\n",
      "Steps: 87124 Loss:1.1112 , Current Loss: 1.0436\n",
      "Steps: 87224 Loss:1.1063 , Current Loss: 1.2490\n",
      "Steps: 87324 Loss:1.1071 , Current Loss: 1.0824\n",
      "Steps: 87424 Loss:1.1069 , Current Loss: 1.0817\n",
      "Steps: 87524 Loss:1.1042 , Current Loss: 1.0665\n",
      "Steps: 87624 Loss:1.0978 , Current Loss: 1.1138\n",
      "Steps: 87724 Loss:1.1059 , Current Loss: 1.0615\n",
      "Steps: 87824 Loss:1.1008 , Current Loss: 1.0034\n",
      "Steps: 87924 Loss:1.1076 , Current Loss: 1.2267\n",
      "Steps: 88024 Loss:1.1082 , Current Loss: 1.1679\n",
      "Steps: 88124 Loss:1.0941 , Current Loss: 1.1029\n",
      "Steps: 88224 Loss:1.1095 , Current Loss: 1.1060\n",
      "Epoch: 5 , Step: 88295 , loss: 1.1059 , Time: 10855.4\n",
      "Model Saved\n",
      "Steps: 88395 Loss:1.1004 , Current Loss: 1.1322\n",
      "Steps: 88495 Loss:1.1126 , Current Loss: 1.1293\n",
      "Steps: 88595 Loss:1.1053 , Current Loss: 0.9637\n",
      "Steps: 88695 Loss:1.0990 , Current Loss: 1.0843\n",
      "Steps: 88795 Loss:1.0961 , Current Loss: 1.1460\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "val_period = 2\n",
    "pre_train_cond = False\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    random = np.random.choice(len(y_train), size=(len(y_train)), replace=False)\n",
    "    x_id_train = x_id_train[random]\n",
    "    y_train = y_train[random]\n",
    "    mask_train = mask_train[random]    \n",
    "    sense_mask_train = sense_mask_train[random]\n",
    "    y_pos_train = y_pos_train[random]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss, step = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, pretrain_cond=pre_train_cond)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_train_logs([step, train_loss, time_taken])\n",
    "    print(\"Epoch: {}\".format(i+1),\", Step: {}\".format(step), \", loss: {0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))\n",
    "    saver.save(sess, save_path=save_dir)                         \n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "    if((i+1)%val_period==0):\n",
    "        start_time = time.time()\n",
    "        val_loss, val_pred, val_true, val_pred_pos, val_true_pos = model(x_id_val, y_val, y_pos_val, mask_val, sense_mask_val, train_cond=False)        \n",
    "        f1_, accu_, f1_pos_, accu_pos_ = eval_score(val_true, val_pred, val_true_pos, val_pred_pos)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_val_logs([f1_, accu_, f1_pos_, accu_pos_, val_loss, time_taken])\n",
    "        print(\"Val: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(val_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "train_loss, train_pred, train_true, train_pred_pos, train_true_pos = model(x_id_train, y_train, y_pos_train, mask_train, sense_mask_train, train_cond=False)        \n",
    "f1_, accu_, f1_pos_, accu_pos_ = etrain_score(train_true, train_pred, train_true_pos, train_pred_pos)\n",
    "time_taken = time.time() - start_time\n",
    "print(\"train: F1 Score:{0:.2f}\".format(f1_), \"Accuracy:{0:.2f}\".format(accu_), \" POS: F1 Score:{0:.2f}\".format(f1_pos_), \"Accuracy:{0:.2f}\".format(accu_pos_), \"Loss:{0:.4f}\".format(train_loss), \", Time: {0:.1f}\".format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver.restore(sess, save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "cs771"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
