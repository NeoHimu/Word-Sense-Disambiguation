{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/aviraj/dataset/raw_preprocess_train','rb') as f:\n",
    "    global_data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/aviraj/dataset/semcor+omsti.gold.key.txt','r') as f:\n",
    "    data_key=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_word_data(checkword):\n",
    "    \n",
    "    dataset_line=[]\n",
    "    for i,list_ in enumerate(global_data): \n",
    "        ind=[idx for idx,it in enumerate(list_[3]) if it==checkword]\n",
    "        for ii in ind:\n",
    "            if list_[2][ii] is not None:\n",
    "                dataset_line.append([list_[2][ii],list_[1],list_[4]])\n",
    "    \n",
    "    print(len(dataset_line))\n",
    "    with open('/data/aviraj/dataset/checkwords/'+checkword + '_data', 'wb') as f:\n",
    "        pickle.dump(dataset_line, f)\n",
    "    with open('/data/aviraj/dataset/checkwords/'+checkword + '_data', 'rb') as f:\n",
    "        data_ = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_frequent_words=[('change', 3074),\n",
    " ('lead', 2987),\n",
    " ('design', 2938),\n",
    " ('open', 2922),\n",
    " ('study', 2920),\n",
    " ('set', 2909),\n",
    " ('call', 2906),\n",
    " ('point', 2855),\n",
    " ('bring', 2836),\n",
    " ('extend', 2832)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3074\n",
      "2987\n",
      "2938\n",
      "2922\n",
      "2920\n",
      "2909\n",
      "2906\n",
      "2855\n",
      "2836\n",
      "2832\n"
     ]
    }
   ],
   "source": [
    "for word in most_frequent_words:\n",
    "    make_word_data(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Glove/vocab_glove', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_words = []\n",
    "for sent in global_data:\n",
    "    train_words.extend(sent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_words), len(set(train_words)), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "unknown_words = []\n",
    "for word in set(train_words):\n",
    "    if word not in vocab:\n",
    "        unknown_words.append(word)\n",
    "        \n",
    "un_counter = collections.Counter(unknown_words)\n",
    "un_counter = dict(un_counter)\n",
    "\n",
    "sorted_un_counter = sorted(un_counter.items(), key=lambda x:x[1], reverse=True)\n",
    "sorted_un_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('million_unknown_words.pickle', 'wb') as f:\n",
    "    pickle.dump(unknown_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted(global_data, key=lambda x:len(x[1]), reverse=True)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs771",
   "language": "python",
   "name": "cs771"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
